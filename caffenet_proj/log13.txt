I0315 01:45:09.181164 17875 caffe.cpp:211] Use CPU.
I0315 01:45:09.537226 17875 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 3000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "models/caffenet_proj/caffenet_train"
solver_mode: CPU
net: "models/caffenet_proj/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0315 01:45:09.537401 17875 solver.cpp:87] Creating training net from net file: models/caffenet_proj/train_val.prototxt
I0315 01:45:09.537788 17875 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0315 01:45:09.537818 17875 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0315 01:45:09.538050 17875 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0315 01:45:09.538182 17875 layer_factory.hpp:77] Creating layer data
I0315 01:45:09.538313 17875 db_lmdb.cpp:35] Opened lmdb examples/imagenet/ilsvrc12_train_lmdb
I0315 01:45:09.593281 17875 net.cpp:86] Creating Layer data
I0315 01:45:09.593338 17875 net.cpp:382] data -> data
I0315 01:45:09.593400 17875 net.cpp:382] data -> label
I0315 01:45:09.593439 17875 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0315 01:45:09.598623 17875 data_layer.cpp:45] output data size: 256,3,227,227
I0315 01:45:10.132323 17875 net.cpp:124] Setting up data
I0315 01:45:10.132377 17875 net.cpp:131] Top shape: 256 3 227 227 (39574272)
I0315 01:45:10.132386 17875 net.cpp:131] Top shape: 256 (256)
I0315 01:45:10.132392 17875 net.cpp:139] Memory required for data: 158298112
I0315 01:45:10.132407 17875 layer_factory.hpp:77] Creating layer conv1
I0315 01:45:10.132438 17875 net.cpp:86] Creating Layer conv1
I0315 01:45:10.132449 17875 net.cpp:408] conv1 <- data
I0315 01:45:10.132468 17875 net.cpp:382] conv1 -> conv1
I0315 01:45:12.127555 17875 net.cpp:124] Setting up conv1
I0315 01:45:12.127622 17875 net.cpp:131] Top shape: 256 96 55 55 (74342400)
I0315 01:45:12.127635 17875 net.cpp:139] Memory required for data: 455667712
I0315 01:45:12.127682 17875 layer_factory.hpp:77] Creating layer relu1
I0315 01:45:12.127710 17875 net.cpp:86] Creating Layer relu1
I0315 01:45:12.127723 17875 net.cpp:408] relu1 <- conv1
I0315 01:45:12.127739 17875 net.cpp:369] relu1 -> conv1 (in-place)
I0315 01:45:12.128312 17875 net.cpp:124] Setting up relu1
I0315 01:45:12.128340 17875 net.cpp:131] Top shape: 256 96 55 55 (74342400)
I0315 01:45:12.128350 17875 net.cpp:139] Memory required for data: 753037312
I0315 01:45:12.128361 17875 layer_factory.hpp:77] Creating layer pool1
I0315 01:45:12.128379 17875 net.cpp:86] Creating Layer pool1
I0315 01:45:12.128391 17875 net.cpp:408] pool1 <- conv1
I0315 01:45:12.128407 17875 net.cpp:382] pool1 -> pool1
I0315 01:45:12.128444 17875 net.cpp:124] Setting up pool1
I0315 01:45:12.128461 17875 net.cpp:131] Top shape: 256 96 27 27 (17915904)
I0315 01:45:12.128470 17875 net.cpp:139] Memory required for data: 824700928
I0315 01:45:12.128480 17875 layer_factory.hpp:77] Creating layer norm1
I0315 01:45:12.128504 17875 net.cpp:86] Creating Layer norm1
I0315 01:45:12.128515 17875 net.cpp:408] norm1 <- pool1
I0315 01:45:12.128530 17875 net.cpp:382] norm1 -> norm1
I0315 01:45:12.128888 17875 net.cpp:124] Setting up norm1
I0315 01:45:12.128935 17875 net.cpp:131] Top shape: 256 96 27 27 (17915904)
I0315 01:45:12.128947 17875 net.cpp:139] Memory required for data: 896364544
I0315 01:45:12.128957 17875 layer_factory.hpp:77] Creating layer conv2
I0315 01:45:12.128983 17875 net.cpp:86] Creating Layer conv2
I0315 01:45:12.128993 17875 net.cpp:408] conv2 <- norm1
I0315 01:45:12.129009 17875 net.cpp:382] conv2 -> conv2
I0315 01:45:12.140377 17875 net.cpp:124] Setting up conv2
I0315 01:45:12.140419 17875 net.cpp:131] Top shape: 256 256 27 27 (47775744)
I0315 01:45:12.140429 17875 net.cpp:139] Memory required for data: 1087467520
I0315 01:45:12.140453 17875 layer_factory.hpp:77] Creating layer relu2
I0315 01:45:12.140481 17875 net.cpp:86] Creating Layer relu2
I0315 01:45:12.140493 17875 net.cpp:408] relu2 <- conv2
I0315 01:45:12.140508 17875 net.cpp:369] relu2 -> conv2 (in-place)
I0315 01:45:12.140908 17875 net.cpp:124] Setting up relu2
I0315 01:45:12.140930 17875 net.cpp:131] Top shape: 256 256 27 27 (47775744)
I0315 01:45:12.140938 17875 net.cpp:139] Memory required for data: 1278570496
I0315 01:45:12.140947 17875 layer_factory.hpp:77] Creating layer pool2
I0315 01:45:12.140965 17875 net.cpp:86] Creating Layer pool2
I0315 01:45:12.140974 17875 net.cpp:408] pool2 <- conv2
I0315 01:45:12.140988 17875 net.cpp:382] pool2 -> pool2
I0315 01:45:12.141013 17875 net.cpp:124] Setting up pool2
I0315 01:45:12.141027 17875 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0315 01:45:12.141036 17875 net.cpp:139] Memory required for data: 1322872832
I0315 01:45:12.141043 17875 layer_factory.hpp:77] Creating layer norm2
I0315 01:45:12.141065 17875 net.cpp:86] Creating Layer norm2
I0315 01:45:12.141075 17875 net.cpp:408] norm2 <- pool2
I0315 01:45:12.141088 17875 net.cpp:382] norm2 -> norm2
I0315 01:45:12.141643 17875 net.cpp:124] Setting up norm2
I0315 01:45:12.141670 17875 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0315 01:45:12.141680 17875 net.cpp:139] Memory required for data: 1367175168
I0315 01:45:12.141690 17875 layer_factory.hpp:77] Creating layer conv3
I0315 01:45:12.141713 17875 net.cpp:86] Creating Layer conv3
I0315 01:45:12.141724 17875 net.cpp:408] conv3 <- norm2
I0315 01:45:12.141741 17875 net.cpp:382] conv3 -> conv3
I0315 01:45:12.380678 17875 net.cpp:124] Setting up conv3
I0315 01:45:12.380731 17875 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0315 01:45:12.380738 17875 net.cpp:139] Memory required for data: 1433628672
I0315 01:45:12.380760 17875 layer_factory.hpp:77] Creating layer relu3
I0315 01:45:12.380779 17875 net.cpp:86] Creating Layer relu3
I0315 01:45:12.380787 17875 net.cpp:408] relu3 <- conv3
I0315 01:45:12.380798 17875 net.cpp:369] relu3 -> conv3 (in-place)
I0315 01:45:12.381016 17875 net.cpp:124] Setting up relu3
I0315 01:45:12.381031 17875 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0315 01:45:12.381036 17875 net.cpp:139] Memory required for data: 1500082176
I0315 01:45:12.381042 17875 layer_factory.hpp:77] Creating layer conv4
I0315 01:45:12.381063 17875 net.cpp:86] Creating Layer conv4
I0315 01:45:12.381070 17875 net.cpp:408] conv4 <- conv3
I0315 01:45:12.381079 17875 net.cpp:382] conv4 -> conv4
I0315 01:45:12.393100 17875 net.cpp:124] Setting up conv4
I0315 01:45:12.393123 17875 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0315 01:45:12.393129 17875 net.cpp:139] Memory required for data: 1566535680
I0315 01:45:12.393141 17875 layer_factory.hpp:77] Creating layer relu4
I0315 01:45:12.393151 17875 net.cpp:86] Creating Layer relu4
I0315 01:45:12.393157 17875 net.cpp:408] relu4 <- conv4
I0315 01:45:12.393167 17875 net.cpp:369] relu4 -> conv4 (in-place)
I0315 01:45:12.393404 17875 net.cpp:124] Setting up relu4
I0315 01:45:12.393417 17875 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0315 01:45:12.393422 17875 net.cpp:139] Memory required for data: 1632989184
I0315 01:45:12.393429 17875 layer_factory.hpp:77] Creating layer conv5
I0315 01:45:12.393445 17875 net.cpp:86] Creating Layer conv5
I0315 01:45:12.393452 17875 net.cpp:408] conv5 <- conv4
I0315 01:45:12.393476 17875 net.cpp:382] conv5 -> conv5
I0315 01:45:12.402305 17875 net.cpp:124] Setting up conv5
I0315 01:45:12.402326 17875 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0315 01:45:12.402333 17875 net.cpp:139] Memory required for data: 1677291520
I0315 01:45:12.402349 17875 layer_factory.hpp:77] Creating layer relu5
I0315 01:45:12.402359 17875 net.cpp:86] Creating Layer relu5
I0315 01:45:12.402366 17875 net.cpp:408] relu5 <- conv5
I0315 01:45:12.402375 17875 net.cpp:369] relu5 -> conv5 (in-place)
I0315 01:45:12.402596 17875 net.cpp:124] Setting up relu5
I0315 01:45:12.402612 17875 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0315 01:45:12.402617 17875 net.cpp:139] Memory required for data: 1721593856
I0315 01:45:12.402623 17875 layer_factory.hpp:77] Creating layer pool5
I0315 01:45:12.402634 17875 net.cpp:86] Creating Layer pool5
I0315 01:45:12.402640 17875 net.cpp:408] pool5 <- conv5
I0315 01:45:12.402652 17875 net.cpp:382] pool5 -> pool5
I0315 01:45:12.402667 17875 net.cpp:124] Setting up pool5
I0315 01:45:12.402676 17875 net.cpp:131] Top shape: 256 256 6 6 (2359296)
I0315 01:45:12.402681 17875 net.cpp:139] Memory required for data: 1731031040
I0315 01:45:12.402686 17875 layer_factory.hpp:77] Creating layer fc6
I0315 01:45:12.402703 17875 net.cpp:86] Creating Layer fc6
I0315 01:45:12.402709 17875 net.cpp:408] fc6 <- pool5
I0315 01:45:12.402717 17875 net.cpp:382] fc6 -> fc6
I0315 01:45:13.316448 17875 net.cpp:124] Setting up fc6
I0315 01:45:13.316504 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.316511 17875 net.cpp:139] Memory required for data: 1735225344
I0315 01:45:13.316526 17875 layer_factory.hpp:77] Creating layer relu6
I0315 01:45:13.316541 17875 net.cpp:86] Creating Layer relu6
I0315 01:45:13.316548 17875 net.cpp:408] relu6 <- fc6
I0315 01:45:13.316560 17875 net.cpp:369] relu6 -> fc6 (in-place)
I0315 01:45:13.317168 17875 net.cpp:124] Setting up relu6
I0315 01:45:13.317184 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.317190 17875 net.cpp:139] Memory required for data: 1739419648
I0315 01:45:13.317196 17875 layer_factory.hpp:77] Creating layer drop6
I0315 01:45:13.317209 17875 net.cpp:86] Creating Layer drop6
I0315 01:45:13.317216 17875 net.cpp:408] drop6 <- fc6
I0315 01:45:13.317225 17875 net.cpp:369] drop6 -> fc6 (in-place)
I0315 01:45:13.317242 17875 net.cpp:124] Setting up drop6
I0315 01:45:13.317253 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.317258 17875 net.cpp:139] Memory required for data: 1743613952
I0315 01:45:13.317265 17875 layer_factory.hpp:77] Creating layer fc7
I0315 01:45:13.317276 17875 net.cpp:86] Creating Layer fc7
I0315 01:45:13.317281 17875 net.cpp:408] fc7 <- fc6
I0315 01:45:13.317289 17875 net.cpp:382] fc7 -> fc7
I0315 01:45:13.691203 17875 net.cpp:124] Setting up fc7
I0315 01:45:13.691258 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.691264 17875 net.cpp:139] Memory required for data: 1747808256
I0315 01:45:13.691280 17875 layer_factory.hpp:77] Creating layer relu7
I0315 01:45:13.691294 17875 net.cpp:86] Creating Layer relu7
I0315 01:45:13.691301 17875 net.cpp:408] relu7 <- fc7
I0315 01:45:13.691313 17875 net.cpp:369] relu7 -> fc7 (in-place)
I0315 01:45:13.691640 17875 net.cpp:124] Setting up relu7
I0315 01:45:13.691654 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.691660 17875 net.cpp:139] Memory required for data: 1752002560
I0315 01:45:13.691666 17875 layer_factory.hpp:77] Creating layer drop7
I0315 01:45:13.691678 17875 net.cpp:86] Creating Layer drop7
I0315 01:45:13.691684 17875 net.cpp:408] drop7 <- fc7
I0315 01:45:13.691691 17875 net.cpp:369] drop7 -> fc7 (in-place)
I0315 01:45:13.691704 17875 net.cpp:124] Setting up drop7
I0315 01:45:13.691710 17875 net.cpp:131] Top shape: 256 4096 (1048576)
I0315 01:45:13.691715 17875 net.cpp:139] Memory required for data: 1756196864
I0315 01:45:13.691721 17875 layer_factory.hpp:77] Creating layer fc8
I0315 01:45:13.691735 17875 net.cpp:86] Creating Layer fc8
I0315 01:45:13.691740 17875 net.cpp:408] fc8 <- fc7
I0315 01:45:13.691762 17875 net.cpp:382] fc8 -> fc8
I0315 01:45:13.777269 17875 net.cpp:124] Setting up fc8
I0315 01:45:13.777320 17875 net.cpp:131] Top shape: 256 1000 (256000)
I0315 01:45:13.777325 17875 net.cpp:139] Memory required for data: 1757220864
I0315 01:45:13.777340 17875 layer_factory.hpp:77] Creating layer loss
I0315 01:45:13.777365 17875 net.cpp:86] Creating Layer loss
I0315 01:45:13.777374 17875 net.cpp:408] loss <- fc8
I0315 01:45:13.777384 17875 net.cpp:408] loss <- label
I0315 01:45:13.777400 17875 net.cpp:382] loss -> loss
I0315 01:45:13.777425 17875 layer_factory.hpp:77] Creating layer loss
I0315 01:45:13.778425 17875 net.cpp:124] Setting up loss
I0315 01:45:13.778442 17875 net.cpp:131] Top shape: (1)
I0315 01:45:13.778448 17875 net.cpp:134]     with loss weight 1
I0315 01:45:13.778476 17875 net.cpp:139] Memory required for data: 1757220868
I0315 01:45:13.778482 17875 net.cpp:200] loss needs backward computation.
I0315 01:45:13.778493 17875 net.cpp:200] fc8 needs backward computation.
I0315 01:45:13.778501 17875 net.cpp:200] drop7 needs backward computation.
I0315 01:45:13.778506 17875 net.cpp:200] relu7 needs backward computation.
I0315 01:45:13.778512 17875 net.cpp:200] fc7 needs backward computation.
I0315 01:45:13.778517 17875 net.cpp:200] drop6 needs backward computation.
I0315 01:45:13.778522 17875 net.cpp:200] relu6 needs backward computation.
I0315 01:45:13.778528 17875 net.cpp:200] fc6 needs backward computation.
I0315 01:45:13.778533 17875 net.cpp:200] pool5 needs backward computation.
I0315 01:45:13.778539 17875 net.cpp:200] relu5 needs backward computation.
I0315 01:45:13.778545 17875 net.cpp:200] conv5 needs backward computation.
I0315 01:45:13.778551 17875 net.cpp:200] relu4 needs backward computation.
I0315 01:45:13.778558 17875 net.cpp:200] conv4 needs backward computation.
I0315 01:45:13.778563 17875 net.cpp:200] relu3 needs backward computation.
I0315 01:45:13.778569 17875 net.cpp:200] conv3 needs backward computation.
I0315 01:45:13.778575 17875 net.cpp:200] norm2 needs backward computation.
I0315 01:45:13.778583 17875 net.cpp:200] pool2 needs backward computation.
I0315 01:45:13.778589 17875 net.cpp:200] relu2 needs backward computation.
I0315 01:45:13.778594 17875 net.cpp:200] conv2 needs backward computation.
I0315 01:45:13.778600 17875 net.cpp:200] norm1 needs backward computation.
I0315 01:45:13.778606 17875 net.cpp:200] pool1 needs backward computation.
I0315 01:45:13.778612 17875 net.cpp:200] relu1 needs backward computation.
I0315 01:45:13.778619 17875 net.cpp:200] conv1 needs backward computation.
I0315 01:45:13.778625 17875 net.cpp:202] data does not need backward computation.
I0315 01:45:13.778632 17875 net.cpp:244] This network produces output loss
I0315 01:45:13.778652 17875 net.cpp:257] Network initialization done.
I0315 01:45:13.779036 17875 solver.cpp:173] Creating test net (#0) specified by net file: models/caffenet_proj/train_val.prototxt
I0315 01:45:13.779083 17875 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0315 01:45:13.779326 17875 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0315 01:45:13.779484 17875 layer_factory.hpp:77] Creating layer data
I0315 01:45:13.779579 17875 db_lmdb.cpp:35] Opened lmdb examples/imagenet/ilsvrc12_val_lmdb
I0315 01:45:13.779609 17875 net.cpp:86] Creating Layer data
I0315 01:45:13.779623 17875 net.cpp:382] data -> data
I0315 01:45:13.779636 17875 net.cpp:382] data -> label
I0315 01:45:13.779649 17875 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0315 01:45:13.781447 17875 data_layer.cpp:45] output data size: 50,3,227,227
I0315 01:45:14.031540 17875 net.cpp:124] Setting up data
I0315 01:45:14.031594 17875 net.cpp:131] Top shape: 50 3 227 227 (7729350)
I0315 01:45:14.031601 17875 net.cpp:131] Top shape: 50 (50)
I0315 01:45:14.031607 17875 net.cpp:139] Memory required for data: 30917600
I0315 01:45:14.031617 17875 layer_factory.hpp:77] Creating layer label_data_1_split
I0315 01:45:14.031635 17875 net.cpp:86] Creating Layer label_data_1_split
I0315 01:45:14.031642 17875 net.cpp:408] label_data_1_split <- label
I0315 01:45:14.031653 17875 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0315 01:45:14.031671 17875 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0315 01:45:14.031685 17875 net.cpp:124] Setting up label_data_1_split
I0315 01:45:14.031693 17875 net.cpp:131] Top shape: 50 (50)
I0315 01:45:14.031699 17875 net.cpp:131] Top shape: 50 (50)
I0315 01:45:14.031704 17875 net.cpp:139] Memory required for data: 30918000
I0315 01:45:14.031710 17875 layer_factory.hpp:77] Creating layer conv1
I0315 01:45:14.031728 17875 net.cpp:86] Creating Layer conv1
I0315 01:45:14.031733 17875 net.cpp:408] conv1 <- data
I0315 01:45:14.031744 17875 net.cpp:382] conv1 -> conv1
I0315 01:45:14.033512 17875 net.cpp:124] Setting up conv1
I0315 01:45:14.033530 17875 net.cpp:131] Top shape: 50 96 55 55 (14520000)
I0315 01:45:14.033537 17875 net.cpp:139] Memory required for data: 88998000
I0315 01:45:14.033553 17875 layer_factory.hpp:77] Creating layer relu1
I0315 01:45:14.033563 17875 net.cpp:86] Creating Layer relu1
I0315 01:45:14.033570 17875 net.cpp:408] relu1 <- conv1
I0315 01:45:14.033578 17875 net.cpp:369] relu1 -> conv1 (in-place)
I0315 01:45:14.033778 17875 net.cpp:124] Setting up relu1
I0315 01:45:14.033793 17875 net.cpp:131] Top shape: 50 96 55 55 (14520000)
I0315 01:45:14.033798 17875 net.cpp:139] Memory required for data: 147078000
I0315 01:45:14.033804 17875 layer_factory.hpp:77] Creating layer pool1
I0315 01:45:14.033818 17875 net.cpp:86] Creating Layer pool1
I0315 01:45:14.033823 17875 net.cpp:408] pool1 <- conv1
I0315 01:45:14.033833 17875 net.cpp:382] pool1 -> pool1
I0315 01:45:14.033848 17875 net.cpp:124] Setting up pool1
I0315 01:45:14.033855 17875 net.cpp:131] Top shape: 50 96 27 27 (3499200)
I0315 01:45:14.033861 17875 net.cpp:139] Memory required for data: 161074800
I0315 01:45:14.033866 17875 layer_factory.hpp:77] Creating layer norm1
I0315 01:45:14.033877 17875 net.cpp:86] Creating Layer norm1
I0315 01:45:14.033884 17875 net.cpp:408] norm1 <- pool1
I0315 01:45:14.033891 17875 net.cpp:382] norm1 -> norm1
I0315 01:45:14.034245 17875 net.cpp:124] Setting up norm1
I0315 01:45:14.034260 17875 net.cpp:131] Top shape: 50 96 27 27 (3499200)
I0315 01:45:14.034266 17875 net.cpp:139] Memory required for data: 175071600
I0315 01:45:14.034272 17875 layer_factory.hpp:77] Creating layer conv2
I0315 01:45:14.034286 17875 net.cpp:86] Creating Layer conv2
I0315 01:45:14.034292 17875 net.cpp:408] conv2 <- norm1
I0315 01:45:14.034302 17875 net.cpp:382] conv2 -> conv2
I0315 01:45:14.040899 17875 net.cpp:124] Setting up conv2
I0315 01:45:14.040948 17875 net.cpp:131] Top shape: 50 256 27 27 (9331200)
I0315 01:45:14.040954 17875 net.cpp:139] Memory required for data: 212396400
I0315 01:45:14.040974 17875 layer_factory.hpp:77] Creating layer relu2
I0315 01:45:14.040989 17875 net.cpp:86] Creating Layer relu2
I0315 01:45:14.040997 17875 net.cpp:408] relu2 <- conv2
I0315 01:45:14.041007 17875 net.cpp:369] relu2 -> conv2 (in-place)
I0315 01:45:14.041395 17875 net.cpp:124] Setting up relu2
I0315 01:45:14.041411 17875 net.cpp:131] Top shape: 50 256 27 27 (9331200)
I0315 01:45:14.041431 17875 net.cpp:139] Memory required for data: 249721200
I0315 01:45:14.041450 17875 layer_factory.hpp:77] Creating layer pool2
I0315 01:45:14.041465 17875 net.cpp:86] Creating Layer pool2
I0315 01:45:14.041471 17875 net.cpp:408] pool2 <- conv2
I0315 01:45:14.041482 17875 net.cpp:382] pool2 -> pool2
I0315 01:45:14.041501 17875 net.cpp:124] Setting up pool2
I0315 01:45:14.041512 17875 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0315 01:45:14.041517 17875 net.cpp:139] Memory required for data: 258374000
I0315 01:45:14.041522 17875 layer_factory.hpp:77] Creating layer norm2
I0315 01:45:14.041533 17875 net.cpp:86] Creating Layer norm2
I0315 01:45:14.041539 17875 net.cpp:408] norm2 <- pool2
I0315 01:45:14.041548 17875 net.cpp:382] norm2 -> norm2
I0315 01:45:14.041766 17875 net.cpp:124] Setting up norm2
I0315 01:45:14.041780 17875 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0315 01:45:14.041786 17875 net.cpp:139] Memory required for data: 267026800
I0315 01:45:14.041791 17875 layer_factory.hpp:77] Creating layer conv3
I0315 01:45:14.041810 17875 net.cpp:86] Creating Layer conv3
I0315 01:45:14.041817 17875 net.cpp:408] conv3 <- norm2
I0315 01:45:14.041829 17875 net.cpp:382] conv3 -> conv3
I0315 01:45:14.060577 17875 net.cpp:124] Setting up conv3
I0315 01:45:14.060627 17875 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0315 01:45:14.060634 17875 net.cpp:139] Memory required for data: 280006000
I0315 01:45:14.060654 17875 layer_factory.hpp:77] Creating layer relu3
I0315 01:45:14.060669 17875 net.cpp:86] Creating Layer relu3
I0315 01:45:14.060678 17875 net.cpp:408] relu3 <- conv3
I0315 01:45:14.060690 17875 net.cpp:369] relu3 -> conv3 (in-place)
I0315 01:45:14.061067 17875 net.cpp:124] Setting up relu3
I0315 01:45:14.061084 17875 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0315 01:45:14.061089 17875 net.cpp:139] Memory required for data: 292985200
I0315 01:45:14.061095 17875 layer_factory.hpp:77] Creating layer conv4
I0315 01:45:14.061112 17875 net.cpp:86] Creating Layer conv4
I0315 01:45:14.061120 17875 net.cpp:408] conv4 <- conv3
I0315 01:45:14.061131 17875 net.cpp:382] conv4 -> conv4
I0315 01:45:14.073429 17875 net.cpp:124] Setting up conv4
I0315 01:45:14.073479 17875 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0315 01:45:14.073487 17875 net.cpp:139] Memory required for data: 305964400
I0315 01:45:14.073501 17875 layer_factory.hpp:77] Creating layer relu4
I0315 01:45:14.073521 17875 net.cpp:86] Creating Layer relu4
I0315 01:45:14.073530 17875 net.cpp:408] relu4 <- conv4
I0315 01:45:14.073545 17875 net.cpp:369] relu4 -> conv4 (in-place)
I0315 01:45:14.073938 17875 net.cpp:124] Setting up relu4
I0315 01:45:14.073954 17875 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0315 01:45:14.073961 17875 net.cpp:139] Memory required for data: 318943600
I0315 01:45:14.073966 17875 layer_factory.hpp:77] Creating layer conv5
I0315 01:45:14.073987 17875 net.cpp:86] Creating Layer conv5
I0315 01:45:14.073993 17875 net.cpp:408] conv5 <- conv4
I0315 01:45:14.074007 17875 net.cpp:382] conv5 -> conv5
I0315 01:45:14.083017 17875 net.cpp:124] Setting up conv5
I0315 01:45:14.083065 17875 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0315 01:45:14.083071 17875 net.cpp:139] Memory required for data: 327596400
I0315 01:45:14.083096 17875 layer_factory.hpp:77] Creating layer relu5
I0315 01:45:14.083111 17875 net.cpp:86] Creating Layer relu5
I0315 01:45:14.083118 17875 net.cpp:408] relu5 <- conv5
I0315 01:45:14.083133 17875 net.cpp:369] relu5 -> conv5 (in-place)
I0315 01:45:14.083358 17875 net.cpp:124] Setting up relu5
I0315 01:45:14.083372 17875 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0315 01:45:14.083377 17875 net.cpp:139] Memory required for data: 336249200
I0315 01:45:14.083384 17875 layer_factory.hpp:77] Creating layer pool5
I0315 01:45:14.083400 17875 net.cpp:86] Creating Layer pool5
I0315 01:45:14.083407 17875 net.cpp:408] pool5 <- conv5
I0315 01:45:14.083416 17875 net.cpp:382] pool5 -> pool5
I0315 01:45:14.083432 17875 net.cpp:124] Setting up pool5
I0315 01:45:14.083441 17875 net.cpp:131] Top shape: 50 256 6 6 (460800)
I0315 01:45:14.083468 17875 net.cpp:139] Memory required for data: 338092400
I0315 01:45:14.083474 17875 layer_factory.hpp:77] Creating layer fc6
I0315 01:45:14.083489 17875 net.cpp:86] Creating Layer fc6
I0315 01:45:14.083497 17875 net.cpp:408] fc6 <- pool5
I0315 01:45:14.083508 17875 net.cpp:382] fc6 -> fc6
I0315 01:45:14.920123 17875 net.cpp:124] Setting up fc6
I0315 01:45:14.920176 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:14.920181 17875 net.cpp:139] Memory required for data: 338911600
I0315 01:45:14.920198 17875 layer_factory.hpp:77] Creating layer relu6
I0315 01:45:14.920214 17875 net.cpp:86] Creating Layer relu6
I0315 01:45:14.920223 17875 net.cpp:408] relu6 <- fc6
I0315 01:45:14.920234 17875 net.cpp:369] relu6 -> fc6 (in-place)
I0315 01:45:14.920820 17875 net.cpp:124] Setting up relu6
I0315 01:45:14.920836 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:14.920842 17875 net.cpp:139] Memory required for data: 339730800
I0315 01:45:14.920848 17875 layer_factory.hpp:77] Creating layer drop6
I0315 01:45:14.920861 17875 net.cpp:86] Creating Layer drop6
I0315 01:45:14.920867 17875 net.cpp:408] drop6 <- fc6
I0315 01:45:14.920876 17875 net.cpp:369] drop6 -> fc6 (in-place)
I0315 01:45:14.920888 17875 net.cpp:124] Setting up drop6
I0315 01:45:14.920897 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:14.920902 17875 net.cpp:139] Memory required for data: 340550000
I0315 01:45:14.920907 17875 layer_factory.hpp:77] Creating layer fc7
I0315 01:45:14.920919 17875 net.cpp:86] Creating Layer fc7
I0315 01:45:14.920925 17875 net.cpp:408] fc7 <- fc6
I0315 01:45:14.920934 17875 net.cpp:382] fc7 -> fc7
I0315 01:45:15.296018 17875 net.cpp:124] Setting up fc7
I0315 01:45:15.296070 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:15.296077 17875 net.cpp:139] Memory required for data: 341369200
I0315 01:45:15.296092 17875 layer_factory.hpp:77] Creating layer relu7
I0315 01:45:15.296108 17875 net.cpp:86] Creating Layer relu7
I0315 01:45:15.296115 17875 net.cpp:408] relu7 <- fc7
I0315 01:45:15.296128 17875 net.cpp:369] relu7 -> fc7 (in-place)
I0315 01:45:15.296473 17875 net.cpp:124] Setting up relu7
I0315 01:45:15.296486 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:15.296492 17875 net.cpp:139] Memory required for data: 342188400
I0315 01:45:15.296499 17875 layer_factory.hpp:77] Creating layer drop7
I0315 01:45:15.296509 17875 net.cpp:86] Creating Layer drop7
I0315 01:45:15.296514 17875 net.cpp:408] drop7 <- fc7
I0315 01:45:15.296525 17875 net.cpp:369] drop7 -> fc7 (in-place)
I0315 01:45:15.296537 17875 net.cpp:124] Setting up drop7
I0315 01:45:15.296545 17875 net.cpp:131] Top shape: 50 4096 (204800)
I0315 01:45:15.296550 17875 net.cpp:139] Memory required for data: 343007600
I0315 01:45:15.296556 17875 layer_factory.hpp:77] Creating layer fc8
I0315 01:45:15.296566 17875 net.cpp:86] Creating Layer fc8
I0315 01:45:15.296572 17875 net.cpp:408] fc8 <- fc7
I0315 01:45:15.296583 17875 net.cpp:382] fc8 -> fc8
I0315 01:45:15.385787 17875 net.cpp:124] Setting up fc8
I0315 01:45:15.385838 17875 net.cpp:131] Top shape: 50 1000 (50000)
I0315 01:45:15.385843 17875 net.cpp:139] Memory required for data: 343207600
I0315 01:45:15.385857 17875 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0315 01:45:15.385871 17875 net.cpp:86] Creating Layer fc8_fc8_0_split
I0315 01:45:15.385879 17875 net.cpp:408] fc8_fc8_0_split <- fc8
I0315 01:45:15.385893 17875 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0315 01:45:15.385908 17875 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0315 01:45:15.385921 17875 net.cpp:124] Setting up fc8_fc8_0_split
I0315 01:45:15.385927 17875 net.cpp:131] Top shape: 50 1000 (50000)
I0315 01:45:15.385934 17875 net.cpp:131] Top shape: 50 1000 (50000)
I0315 01:45:15.385938 17875 net.cpp:139] Memory required for data: 343607600
I0315 01:45:15.385944 17875 layer_factory.hpp:77] Creating layer accuracy
I0315 01:45:15.385957 17875 net.cpp:86] Creating Layer accuracy
I0315 01:45:15.385963 17875 net.cpp:408] accuracy <- fc8_fc8_0_split_0
I0315 01:45:15.385982 17875 net.cpp:408] accuracy <- label_data_1_split_0
I0315 01:45:15.386008 17875 net.cpp:382] accuracy -> accuracy
I0315 01:45:15.386023 17875 net.cpp:124] Setting up accuracy
I0315 01:45:15.386030 17875 net.cpp:131] Top shape: (1)
I0315 01:45:15.386035 17875 net.cpp:139] Memory required for data: 343607604
I0315 01:45:15.386040 17875 layer_factory.hpp:77] Creating layer loss
I0315 01:45:15.386049 17875 net.cpp:86] Creating Layer loss
I0315 01:45:15.386055 17875 net.cpp:408] loss <- fc8_fc8_0_split_1
I0315 01:45:15.386062 17875 net.cpp:408] loss <- label_data_1_split_1
I0315 01:45:15.386070 17875 net.cpp:382] loss -> loss
I0315 01:45:15.386082 17875 layer_factory.hpp:77] Creating layer loss
I0315 01:45:15.386765 17875 net.cpp:124] Setting up loss
I0315 01:45:15.386783 17875 net.cpp:131] Top shape: (1)
I0315 01:45:15.386790 17875 net.cpp:134]     with loss weight 1
I0315 01:45:15.386808 17875 net.cpp:139] Memory required for data: 343607608
I0315 01:45:15.386814 17875 net.cpp:200] loss needs backward computation.
I0315 01:45:15.386821 17875 net.cpp:202] accuracy does not need backward computation.
I0315 01:45:15.386828 17875 net.cpp:200] fc8_fc8_0_split needs backward computation.
I0315 01:45:15.386834 17875 net.cpp:200] fc8 needs backward computation.
I0315 01:45:15.386840 17875 net.cpp:200] drop7 needs backward computation.
I0315 01:45:15.386847 17875 net.cpp:200] relu7 needs backward computation.
I0315 01:45:15.386852 17875 net.cpp:200] fc7 needs backward computation.
I0315 01:45:15.386857 17875 net.cpp:200] drop6 needs backward computation.
I0315 01:45:15.386863 17875 net.cpp:200] relu6 needs backward computation.
I0315 01:45:15.386868 17875 net.cpp:200] fc6 needs backward computation.
I0315 01:45:15.386874 17875 net.cpp:200] pool5 needs backward computation.
I0315 01:45:15.386880 17875 net.cpp:200] relu5 needs backward computation.
I0315 01:45:15.386886 17875 net.cpp:200] conv5 needs backward computation.
I0315 01:45:15.386891 17875 net.cpp:200] relu4 needs backward computation.
I0315 01:45:15.386898 17875 net.cpp:200] conv4 needs backward computation.
I0315 01:45:15.386904 17875 net.cpp:200] relu3 needs backward computation.
I0315 01:45:15.386909 17875 net.cpp:200] conv3 needs backward computation.
I0315 01:45:15.386914 17875 net.cpp:200] norm2 needs backward computation.
I0315 01:45:15.386920 17875 net.cpp:200] pool2 needs backward computation.
I0315 01:45:15.386926 17875 net.cpp:200] relu2 needs backward computation.
I0315 01:45:15.386932 17875 net.cpp:200] conv2 needs backward computation.
I0315 01:45:15.386937 17875 net.cpp:200] norm1 needs backward computation.
I0315 01:45:15.386943 17875 net.cpp:200] pool1 needs backward computation.
I0315 01:45:15.386950 17875 net.cpp:200] relu1 needs backward computation.
I0315 01:45:15.386955 17875 net.cpp:200] conv1 needs backward computation.
I0315 01:45:15.386961 17875 net.cpp:202] label_data_1_split does not need backward computation.
I0315 01:45:15.386967 17875 net.cpp:202] data does not need backward computation.
I0315 01:45:15.386972 17875 net.cpp:244] This network produces output accuracy
I0315 01:45:15.386979 17875 net.cpp:244] This network produces output loss
I0315 01:45:15.387004 17875 net.cpp:257] Network initialization done.
I0315 01:45:15.387109 17875 solver.cpp:56] Solver scaffolding done.
I0315 01:45:15.387163 17875 caffe.cpp:248] Starting Optimization
I0315 01:45:15.387171 17875 solver.cpp:273] Solving CaffeNet
I0315 01:45:15.387176 17875 solver.cpp:274] Learning Rate Policy: fixed
I0315 01:45:15.913987 17875 solver.cpp:331] Iteration 0, Testing net (#0)
I0315 01:57:39.171859 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0008
I0315 01:57:39.171988 17875 solver.cpp:398]     Test net output #1: loss = 7.12047 (* 1 = 7.12047 loss)
I0315 01:59:56.910923 17875 solver.cpp:219] Iteration 0 (0 iter/s, 881.523s/20 iters), loss = 7.34966
I0315 01:59:56.911145 17875 solver.cpp:238]     Train net output #0: loss = 7.34966 (* 1 = 7.34966 loss)
I0315 01:59:56.911173 17875 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0315 02:33:56.143925 17875 solver.cpp:219] Iteration 20 (0.00980761 iter/s, 2039.23s/20 iters), loss = 7.15816
I0315 02:33:56.144220 17875 solver.cpp:238]     Train net output #0: loss = 7.15816 (* 1 = 7.15816 loss)
I0315 02:33:56.144234 17875 sgd_solver.cpp:105] Iteration 20, lr = 0.01
I0315 03:07:47.527250 17875 solver.cpp:219] Iteration 40 (0.00984551 iter/s, 2031.38s/20 iters), loss = 6.94722
I0315 03:07:47.527353 17875 solver.cpp:238]     Train net output #0: loss = 6.94722 (* 1 = 6.94722 loss)
I0315 03:07:47.527364 17875 sgd_solver.cpp:105] Iteration 40, lr = 0.01
I0315 03:41:37.779546 17875 solver.cpp:219] Iteration 60 (0.00985099 iter/s, 2030.25s/20 iters), loss = 6.91001
I0315 03:41:37.779768 17875 solver.cpp:238]     Train net output #0: loss = 6.91001 (* 1 = 6.91001 loss)
I0315 03:41:37.779783 17875 sgd_solver.cpp:105] Iteration 60, lr = 0.01
I0315 04:15:26.995551 17875 solver.cpp:219] Iteration 80 (0.00985603 iter/s, 2029.21s/20 iters), loss = 6.91652
I0315 04:15:26.995779 17875 solver.cpp:238]     Train net output #0: loss = 6.91652 (* 1 = 6.91652 loss)
I0315 04:15:26.995795 17875 sgd_solver.cpp:105] Iteration 80, lr = 0.01
I0315 04:47:35.018476 17875 solver.cpp:331] Iteration 100, Testing net (#0)
I0315 04:59:54.365839 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0008
I0315 04:59:54.366072 17875 solver.cpp:398]     Test net output #1: loss = 6.94508 (* 1 = 6.94508 loss)
I0315 05:01:35.218387 17875 solver.cpp:219] Iteration 100 (0.00722485 iter/s, 2768.22s/20 iters), loss = 6.93418
I0315 05:01:35.218528 17875 solver.cpp:238]     Train net output #0: loss = 6.93418 (* 1 = 6.93418 loss)
I0315 05:01:35.218541 17875 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0315 05:35:24.231874 17875 solver.cpp:219] Iteration 120 (0.00985701 iter/s, 2029.01s/20 iters), loss = 6.88769
I0315 05:35:24.232002 17875 solver.cpp:238]     Train net output #0: loss = 6.88769 (* 1 = 6.88769 loss)
I0315 05:35:24.232014 17875 sgd_solver.cpp:105] Iteration 120, lr = 0.01
I0315 06:09:15.093071 17875 solver.cpp:219] Iteration 140 (0.00984804 iter/s, 2030.86s/20 iters), loss = 6.87924
I0315 06:09:15.093250 17875 solver.cpp:238]     Train net output #0: loss = 6.87924 (* 1 = 6.87924 loss)
I0315 06:09:15.093273 17875 sgd_solver.cpp:105] Iteration 140, lr = 0.01
I0315 06:43:07.954537 17875 solver.cpp:219] Iteration 160 (0.00983835 iter/s, 2032.86s/20 iters), loss = 6.87204
I0315 06:43:07.954638 17875 solver.cpp:238]     Train net output #0: loss = 6.87204 (* 1 = 6.87204 loss)
I0315 06:43:07.954649 17875 sgd_solver.cpp:105] Iteration 160, lr = 0.01
I0315 07:17:02.276114 17875 solver.cpp:219] Iteration 180 (0.00983129 iter/s, 2034.32s/20 iters), loss = 6.89575
I0315 07:17:02.276250 17875 solver.cpp:238]     Train net output #0: loss = 6.89575 (* 1 = 6.89575 loss)
I0315 07:17:02.276262 17875 sgd_solver.cpp:105] Iteration 180, lr = 0.01
I0315 07:49:17.891382 17875 solver.cpp:331] Iteration 200, Testing net (#0)
I0315 08:01:40.993563 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0016
I0315 08:01:40.993705 17875 solver.cpp:398]     Test net output #1: loss = 6.95248 (* 1 = 6.95248 loss)
I0315 08:03:22.216979 17875 solver.cpp:219] Iteration 200 (0.0071944 iter/s, 2779.94s/20 iters), loss = 6.88858
I0315 08:03:22.217075 17875 solver.cpp:238]     Train net output #0: loss = 6.88858 (* 1 = 6.88858 loss)
I0315 08:03:22.217088 17875 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0315 08:37:20.522709 17875 solver.cpp:219] Iteration 220 (0.00981207 iter/s, 2038.31s/20 iters), loss = 6.87594
I0315 08:37:20.522809 17875 solver.cpp:238]     Train net output #0: loss = 6.87594 (* 1 = 6.87594 loss)
I0315 08:37:20.522820 17875 sgd_solver.cpp:105] Iteration 220, lr = 0.01
I0315 09:11:23.563853 17875 solver.cpp:219] Iteration 240 (0.00978933 iter/s, 2043.04s/20 iters), loss = 6.87653
I0315 09:11:23.564043 17875 solver.cpp:238]     Train net output #0: loss = 6.87653 (* 1 = 6.87653 loss)
I0315 09:11:23.564054 17875 sgd_solver.cpp:105] Iteration 240, lr = 0.01
I0315 09:45:30.688613 17875 solver.cpp:219] Iteration 260 (0.0097698 iter/s, 2047.12s/20 iters), loss = 6.88552
I0315 09:45:30.690237 17875 solver.cpp:238]     Train net output #0: loss = 6.88552 (* 1 = 6.88552 loss)
I0315 09:45:30.690249 17875 sgd_solver.cpp:105] Iteration 260, lr = 0.01
I0315 10:19:44.728693 17875 solver.cpp:219] Iteration 280 (0.00973692 iter/s, 2054.04s/20 iters), loss = 6.8826
I0315 10:19:44.728881 17875 solver.cpp:238]     Train net output #0: loss = 6.8826 (* 1 = 6.8826 loss)
I0315 10:19:44.728896 17875 sgd_solver.cpp:105] Iteration 280, lr = 0.01
I0315 10:52:32.351380 17875 solver.cpp:331] Iteration 300, Testing net (#0)
I0315 11:05:11.942101 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0004
I0315 11:05:11.942330 17875 solver.cpp:398]     Test net output #1: loss = 6.95918 (* 1 = 6.95918 loss)
I0315 11:06:55.011454 17875 solver.cpp:219] Iteration 300 (0.00706643 iter/s, 2830.28s/20 iters), loss = 6.85925
I0315 11:06:55.011553 17875 solver.cpp:238]     Train net output #0: loss = 6.85925 (* 1 = 6.85925 loss)
I0315 11:06:55.011564 17875 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0315 11:41:29.532603 17875 solver.cpp:219] Iteration 320 (0.00964078 iter/s, 2074.52s/20 iters), loss = 6.84536
I0315 11:41:29.532701 17875 solver.cpp:238]     Train net output #0: loss = 6.84536 (* 1 = 6.84536 loss)
I0315 11:41:29.532713 17875 sgd_solver.cpp:105] Iteration 320, lr = 0.01
I0315 12:16:07.035852 17875 solver.cpp:219] Iteration 340 (0.00962694 iter/s, 2077.5s/20 iters), loss = 6.86265
I0315 12:16:07.036044 17875 solver.cpp:238]     Train net output #0: loss = 6.86265 (* 1 = 6.86265 loss)
I0315 12:16:07.036059 17875 sgd_solver.cpp:105] Iteration 340, lr = 0.01
I0315 12:50:45.319502 17875 solver.cpp:219] Iteration 360 (0.00962333 iter/s, 2078.28s/20 iters), loss = 6.83393
I0315 12:50:45.319727 17875 solver.cpp:238]     Train net output #0: loss = 6.83393 (* 1 = 6.83393 loss)
I0315 12:50:45.319741 17875 sgd_solver.cpp:105] Iteration 360, lr = 0.01
I0315 13:25:14.609321 17875 solver.cpp:219] Iteration 380 (0.00966515 iter/s, 2069.29s/20 iters), loss = 6.82994
I0315 13:25:14.609421 17875 solver.cpp:238]     Train net output #0: loss = 6.82994 (* 1 = 6.82994 loss)
I0315 13:25:14.609432 17875 sgd_solver.cpp:105] Iteration 380, lr = 0.01
I0315 13:57:57.208531 17875 solver.cpp:331] Iteration 400, Testing net (#0)
I0315 14:10:37.796996 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0014
I0315 14:10:37.797214 17875 solver.cpp:398]     Test net output #1: loss = 6.91655 (* 1 = 6.91655 loss)
I0315 14:12:21.281963 17875 solver.cpp:219] Iteration 400 (0.00707546 iter/s, 2826.67s/20 iters), loss = 6.81301
I0315 14:12:21.282058 17875 solver.cpp:238]     Train net output #0: loss = 6.81301 (* 1 = 6.81301 loss)
I0315 14:12:21.282070 17875 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0315 14:46:41.137836 17875 solver.cpp:219] Iteration 420 (0.00970942 iter/s, 2059.85s/20 iters), loss = 6.77025
I0315 14:46:41.138065 17875 solver.cpp:238]     Train net output #0: loss = 6.77025 (* 1 = 6.77025 loss)
I0315 14:46:41.138079 17875 sgd_solver.cpp:105] Iteration 420, lr = 0.01
I0315 15:21:30.687002 17875 solver.cpp:219] Iteration 440 (0.00957145 iter/s, 2089.55s/20 iters), loss = 6.79755
I0315 15:21:30.687238 17875 solver.cpp:238]     Train net output #0: loss = 6.79755 (* 1 = 6.79755 loss)
I0315 15:21:30.687253 17875 sgd_solver.cpp:105] Iteration 440, lr = 0.01
I0315 15:55:47.059234 17875 solver.cpp:219] Iteration 460 (0.00972587 iter/s, 2056.37s/20 iters), loss = 6.74824
I0315 15:55:47.059335 17875 solver.cpp:238]     Train net output #0: loss = 6.74824 (* 1 = 6.74824 loss)
I0315 15:55:47.059346 17875 sgd_solver.cpp:105] Iteration 460, lr = 0.01
I0315 16:29:54.598943 17875 solver.cpp:219] Iteration 480 (0.00976782 iter/s, 2047.54s/20 iters), loss = 6.78091
I0315 16:29:54.599040 17875 solver.cpp:238]     Train net output #0: loss = 6.78091 (* 1 = 6.78091 loss)
I0315 16:29:54.599051 17875 sgd_solver.cpp:105] Iteration 480, lr = 0.01
I0315 17:02:11.715375 17875 solver.cpp:331] Iteration 500, Testing net (#0)
I0315 17:14:33.990291 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0032
I0315 17:14:33.990517 17875 solver.cpp:398]     Test net output #1: loss = 6.87346 (* 1 = 6.87346 loss)
I0315 17:16:15.027796 17875 solver.cpp:219] Iteration 500 (0.00719314 iter/s, 2780.43s/20 iters), loss = 6.73522
I0315 17:16:15.027937 17875 solver.cpp:238]     Train net output #0: loss = 6.73522 (* 1 = 6.73522 loss)
I0315 17:16:15.027951 17875 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0315 17:50:12.993044 17875 solver.cpp:219] Iteration 520 (0.00981371 iter/s, 2037.96s/20 iters), loss = 6.73218
I0315 17:50:12.993285 17875 solver.cpp:238]     Train net output #0: loss = 6.73218 (* 1 = 6.73218 loss)
I0315 17:50:12.993300 17875 sgd_solver.cpp:105] Iteration 520, lr = 0.01
I0315 18:24:26.582514 17875 solver.cpp:219] Iteration 540 (0.00973905 iter/s, 2053.59s/20 iters), loss = 6.80472
I0315 18:24:26.582609 17875 solver.cpp:238]     Train net output #0: loss = 6.80472 (* 1 = 6.80472 loss)
I0315 18:24:26.582622 17875 sgd_solver.cpp:105] Iteration 540, lr = 0.01
I0315 18:58:34.710017 17875 solver.cpp:219] Iteration 560 (0.00976502 iter/s, 2048.13s/20 iters), loss = 6.75221
I0315 18:58:34.710119 17875 solver.cpp:238]     Train net output #0: loss = 6.75221 (* 1 = 6.75221 loss)
I0315 18:58:34.710131 17875 sgd_solver.cpp:105] Iteration 560, lr = 0.01
I0315 19:32:35.559132 17875 solver.cpp:219] Iteration 580 (0.00979984 iter/s, 2040.85s/20 iters), loss = 6.71528
I0315 19:32:35.559361 17875 solver.cpp:238]     Train net output #0: loss = 6.71528 (* 1 = 6.71528 loss)
I0315 19:32:35.559376 17875 sgd_solver.cpp:105] Iteration 580, lr = 0.01
I0315 20:04:51.685060 17875 solver.cpp:331] Iteration 600, Testing net (#0)
I0315 20:17:12.344257 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0012
I0315 20:17:12.344352 17875 solver.cpp:398]     Test net output #1: loss = 6.86655 (* 1 = 6.86655 loss)
I0315 20:18:53.389813 17875 solver.cpp:219] Iteration 600 (0.00719986 iter/s, 2777.83s/20 iters), loss = 6.71081
I0315 20:18:53.389904 17875 solver.cpp:238]     Train net output #0: loss = 6.71081 (* 1 = 6.71081 loss)
I0315 20:18:53.389915 17875 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0315 20:52:47.954344 17875 solver.cpp:219] Iteration 620 (0.00983012 iter/s, 2034.56s/20 iters), loss = 6.76446
I0315 20:52:47.954447 17875 solver.cpp:238]     Train net output #0: loss = 6.76446 (* 1 = 6.76446 loss)
I0315 20:52:47.954459 17875 sgd_solver.cpp:105] Iteration 620, lr = 0.01
I0315 21:26:53.830965 17875 solver.cpp:219] Iteration 640 (0.00977576 iter/s, 2045.88s/20 iters), loss = 6.69326
I0315 21:26:53.831142 17875 solver.cpp:238]     Train net output #0: loss = 6.69326 (* 1 = 6.69326 loss)
I0315 21:26:53.831156 17875 sgd_solver.cpp:105] Iteration 640, lr = 0.01
I0315 22:00:57.888949 17875 solver.cpp:219] Iteration 660 (0.00978446 iter/s, 2044.06s/20 iters), loss = 6.69938
I0315 22:00:57.889184 17875 solver.cpp:238]     Train net output #0: loss = 6.69938 (* 1 = 6.69938 loss)
I0315 22:00:57.889199 17875 sgd_solver.cpp:105] Iteration 660, lr = 0.01
I0315 22:34:59.020009 17875 solver.cpp:219] Iteration 680 (0.00979849 iter/s, 2041.13s/20 iters), loss = 6.67128
I0315 22:34:59.020252 17875 solver.cpp:238]     Train net output #0: loss = 6.67128 (* 1 = 6.67128 loss)
I0315 22:34:59.020267 17875 sgd_solver.cpp:105] Iteration 680, lr = 0.01
I0315 23:07:16.893101 17875 solver.cpp:331] Iteration 700, Testing net (#0)
I0315 23:19:39.772403 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0014
I0315 23:19:39.775069 17875 solver.cpp:398]     Test net output #1: loss = 6.8322 (* 1 = 6.8322 loss)
I0315 23:21:20.990322 17875 solver.cpp:219] Iteration 700 (0.00718915 iter/s, 2781.97s/20 iters), loss = 6.71757
I0315 23:21:20.990468 17875 solver.cpp:238]     Train net output #0: loss = 6.71757 (* 1 = 6.71757 loss)
I0315 23:21:20.990481 17875 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0315 23:55:18.271174 17875 solver.cpp:219] Iteration 720 (0.00981701 iter/s, 2037.28s/20 iters), loss = 6.63627
I0315 23:55:18.271436 17875 solver.cpp:238]     Train net output #0: loss = 6.63627 (* 1 = 6.63627 loss)
I0315 23:55:18.271451 17875 sgd_solver.cpp:105] Iteration 720, lr = 0.01
I0316 00:29:17.183568 17875 solver.cpp:219] Iteration 740 (0.00980915 iter/s, 2038.91s/20 iters), loss = 6.6583
I0316 00:29:17.187557 17875 solver.cpp:238]     Train net output #0: loss = 6.6583 (* 1 = 6.6583 loss)
I0316 00:29:17.187573 17875 sgd_solver.cpp:105] Iteration 740, lr = 0.01
I0316 01:03:15.922418 17875 solver.cpp:219] Iteration 760 (0.00981001 iter/s, 2038.73s/20 iters), loss = 6.7217
I0316 01:03:15.922605 17875 solver.cpp:238]     Train net output #0: loss = 6.7217 (* 1 = 6.7217 loss)
I0316 01:03:15.922616 17875 sgd_solver.cpp:105] Iteration 760, lr = 0.01
I0316 01:37:18.601809 17875 solver.cpp:219] Iteration 780 (0.00979106 iter/s, 2042.68s/20 iters), loss = 6.60625
I0316 01:37:18.601990 17875 solver.cpp:238]     Train net output #0: loss = 6.60625 (* 1 = 6.60625 loss)
I0316 01:37:18.602015 17875 sgd_solver.cpp:105] Iteration 780, lr = 0.01
I0316 02:09:45.950443 17875 solver.cpp:331] Iteration 800, Testing net (#0)
I0316 02:22:15.261855 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0012
I0316 02:22:15.262076 17875 solver.cpp:398]     Test net output #1: loss = 6.8197 (* 1 = 6.8197 loss)
I0316 02:23:57.115694 17875 solver.cpp:219] Iteration 800 (0.00714665 iter/s, 2798.51s/20 iters), loss = 6.66556
I0316 02:23:57.115880 17875 solver.cpp:238]     Train net output #0: loss = 6.66556 (* 1 = 6.66556 loss)
I0316 02:23:57.115895 17875 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0316 02:58:03.134274 17875 solver.cpp:219] Iteration 820 (0.00977509 iter/s, 2046.02s/20 iters), loss = 6.68221
I0316 02:58:03.134461 17875 solver.cpp:238]     Train net output #0: loss = 6.68221 (* 1 = 6.68221 loss)
I0316 02:58:03.134475 17875 sgd_solver.cpp:105] Iteration 820, lr = 0.01
I0316 03:32:10.078446 17875 solver.cpp:219] Iteration 840 (0.00977067 iter/s, 2046.94s/20 iters), loss = 6.60485
I0316 03:32:10.078547 17875 solver.cpp:238]     Train net output #0: loss = 6.60485 (* 1 = 6.60485 loss)
I0316 03:32:10.078558 17875 sgd_solver.cpp:105] Iteration 840, lr = 0.01
I0316 04:06:21.384714 17875 solver.cpp:219] Iteration 860 (0.00974989 iter/s, 2051.31s/20 iters), loss = 6.53879
I0316 04:06:21.384935 17875 solver.cpp:238]     Train net output #0: loss = 6.53879 (* 1 = 6.53879 loss)
I0316 04:06:21.384950 17875 sgd_solver.cpp:105] Iteration 860, lr = 0.01
I0316 04:40:35.216197 17875 solver.cpp:219] Iteration 880 (0.0097379 iter/s, 2053.83s/20 iters), loss = 6.52238
I0316 04:40:35.216292 17875 solver.cpp:238]     Train net output #0: loss = 6.52238 (* 1 = 6.52238 loss)
I0316 04:40:35.216303 17875 sgd_solver.cpp:105] Iteration 880, lr = 0.01
I0316 05:13:22.459023 17875 solver.cpp:331] Iteration 900, Testing net (#0)
I0316 05:25:40.662441 17908 data_layer.cpp:73] Restarting data prefetching from start.
I0316 05:26:11.359436 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0036
I0316 05:26:11.359611 17875 solver.cpp:398]     Test net output #1: loss = 6.72662 (* 1 = 6.72662 loss)
I0316 05:27:55.485771 17875 solver.cpp:219] Iteration 900 (0.00704159 iter/s, 2840.27s/20 iters), loss = 6.61898
I0316 05:27:55.485954 17875 solver.cpp:238]     Train net output #0: loss = 6.61898 (* 1 = 6.61898 loss)
I0316 05:27:55.485967 17875 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0316 06:02:57.841784 17875 solver.cpp:219] Iteration 920 (0.00951314 iter/s, 2102.35s/20 iters), loss = 6.56872
I0316 06:02:57.841882 17875 solver.cpp:238]     Train net output #0: loss = 6.56872 (* 1 = 6.56872 loss)
I0316 06:02:57.841894 17875 sgd_solver.cpp:105] Iteration 920, lr = 0.01
I0316 06:37:33.002133 17875 solver.cpp:219] Iteration 940 (0.00963781 iter/s, 2075.16s/20 iters), loss = 6.50126
I0316 06:37:33.002233 17875 solver.cpp:238]     Train net output #0: loss = 6.50126 (* 1 = 6.50126 loss)
I0316 06:37:33.002245 17875 sgd_solver.cpp:105] Iteration 940, lr = 0.01
I0316 07:12:23.706693 17875 solver.cpp:219] Iteration 960 (0.00956616 iter/s, 2090.7s/20 iters), loss = 6.62355
I0316 07:12:23.708045 17875 solver.cpp:238]     Train net output #0: loss = 6.62355 (* 1 = 6.62355 loss)
I0316 07:12:23.708072 17875 sgd_solver.cpp:105] Iteration 960, lr = 0.01
I0316 07:47:47.733947 17875 solver.cpp:219] Iteration 980 (0.00941609 iter/s, 2124.02s/20 iters), loss = 6.56927
I0316 07:47:47.734184 17875 solver.cpp:238]     Train net output #0: loss = 6.56927 (* 1 = 6.56927 loss)
I0316 07:47:47.734200 17875 sgd_solver.cpp:105] Iteration 980, lr = 0.01
I0316 08:22:01.254058 17875 solver.cpp:331] Iteration 1000, Testing net (#0)
I0316 08:35:25.101246 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0062
I0316 08:35:25.101342 17875 solver.cpp:398]     Test net output #1: loss = 6.67184 (* 1 = 6.67184 loss)
I0316 08:37:12.614953 17875 solver.cpp:219] Iteration 1000 (0.00674564 iter/s, 2964.88s/20 iters), loss = 6.47975
I0316 08:37:12.615180 17875 solver.cpp:238]     Train net output #0: loss = 6.47975 (* 1 = 6.47975 loss)
I0316 08:37:12.615193 17875 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0316 09:13:05.870618 17875 solver.cpp:219] Iteration 1020 (0.00928826 iter/s, 2153.25s/20 iters), loss = 6.5281
I0316 09:13:05.870715 17875 solver.cpp:238]     Train net output #0: loss = 6.5281 (* 1 = 6.5281 loss)
I0316 09:13:05.870728 17875 sgd_solver.cpp:105] Iteration 1020, lr = 0.01
I0316 09:49:17.236903 17875 solver.cpp:219] Iteration 1040 (0.00921079 iter/s, 2171.37s/20 iters), loss = 6.5035
I0316 09:49:17.237131 17875 solver.cpp:238]     Train net output #0: loss = 6.5035 (* 1 = 6.5035 loss)
I0316 09:49:17.237145 17875 sgd_solver.cpp:105] Iteration 1040, lr = 0.01
I0316 10:25:29.404297 17875 solver.cpp:219] Iteration 1060 (0.00920739 iter/s, 2172.17s/20 iters), loss = 6.49709
I0316 10:25:29.404419 17875 solver.cpp:238]     Train net output #0: loss = 6.49709 (* 1 = 6.49709 loss)
I0316 10:25:29.404431 17875 sgd_solver.cpp:105] Iteration 1060, lr = 0.01
I0316 11:01:43.010999 17875 solver.cpp:219] Iteration 1080 (0.0092013 iter/s, 2173.61s/20 iters), loss = 6.566
I0316 11:01:43.011097 17875 solver.cpp:238]     Train net output #0: loss = 6.566 (* 1 = 6.566 loss)
I0316 11:01:43.011109 17875 sgd_solver.cpp:105] Iteration 1080, lr = 0.01
I0316 11:35:58.389652 17875 solver.cpp:331] Iteration 1100, Testing net (#0)
I0316 11:49:28.437396 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0034
I0316 11:49:28.437616 17875 solver.cpp:398]     Test net output #1: loss = 6.66779 (* 1 = 6.66779 loss)
I0316 11:51:16.371552 17875 solver.cpp:219] Iteration 1100 (0.0067264 iter/s, 2973.36s/20 iters), loss = 6.43501
I0316 11:51:16.371651 17875 solver.cpp:238]     Train net output #0: loss = 6.43501 (* 1 = 6.43501 loss)
I0316 11:51:16.371664 17875 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0316 12:27:41.586091 17875 solver.cpp:219] Iteration 1120 (0.00915242 iter/s, 2185.21s/20 iters), loss = 6.46542
I0316 12:27:41.586186 17875 solver.cpp:238]     Train net output #0: loss = 6.46542 (* 1 = 6.46542 loss)
I0316 12:27:41.586197 17875 sgd_solver.cpp:105] Iteration 1120, lr = 0.01
I0316 13:04:03.287497 17875 solver.cpp:219] Iteration 1140 (0.00916716 iter/s, 2181.7s/20 iters), loss = 6.40656
I0316 13:04:03.287678 17875 solver.cpp:238]     Train net output #0: loss = 6.40656 (* 1 = 6.40656 loss)
I0316 13:04:03.287693 17875 sgd_solver.cpp:105] Iteration 1140, lr = 0.01
I0316 13:40:21.715750 17875 solver.cpp:219] Iteration 1160 (0.00918093 iter/s, 2178.43s/20 iters), loss = 6.4595
I0316 13:40:21.715845 17875 solver.cpp:238]     Train net output #0: loss = 6.4595 (* 1 = 6.4595 loss)
I0316 13:40:21.715857 17875 sgd_solver.cpp:105] Iteration 1160, lr = 0.01
I0316 14:16:56.084830 17875 solver.cpp:219] Iteration 1180 (0.00911424 iter/s, 2194.37s/20 iters), loss = 6.50158
I0316 14:16:56.084930 17875 solver.cpp:238]     Train net output #0: loss = 6.50158 (* 1 = 6.50158 loss)
I0316 14:16:56.084942 17875 sgd_solver.cpp:105] Iteration 1180, lr = 0.01
I0316 14:51:34.432024 17875 solver.cpp:331] Iteration 1200, Testing net (#0)
I0316 15:05:04.404538 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0072
I0316 15:05:04.416795 17875 solver.cpp:398]     Test net output #1: loss = 6.60733 (* 1 = 6.60733 loss)
I0316 15:06:52.408128 17875 solver.cpp:219] Iteration 1200 (0.00667485 iter/s, 2996.32s/20 iters), loss = 6.5425
I0316 15:06:52.408334 17875 solver.cpp:238]     Train net output #0: loss = 6.5425 (* 1 = 6.5425 loss)
I0316 15:06:52.408346 17875 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0316 15:43:21.072762 17875 solver.cpp:219] Iteration 1220 (0.00913799 iter/s, 2188.66s/20 iters), loss = 6.39512
I0316 15:43:21.095413 17875 solver.cpp:238]     Train net output #0: loss = 6.39512 (* 1 = 6.39512 loss)
I0316 15:43:21.095428 17875 sgd_solver.cpp:105] Iteration 1220, lr = 0.01
I0316 16:19:55.669632 17875 solver.cpp:219] Iteration 1240 (0.00911339 iter/s, 2194.57s/20 iters), loss = 6.42553
I0316 16:19:55.669857 17875 solver.cpp:238]     Train net output #0: loss = 6.42553 (* 1 = 6.42553 loss)
I0316 16:19:55.669870 17875 sgd_solver.cpp:105] Iteration 1240, lr = 0.01
I0316 16:56:55.625036 17875 solver.cpp:219] Iteration 1260 (0.00900919 iter/s, 2219.96s/20 iters), loss = 6.32739
I0316 16:56:55.625138 17875 solver.cpp:238]     Train net output #0: loss = 6.32739 (* 1 = 6.32739 loss)
I0316 16:56:55.625150 17875 sgd_solver.cpp:105] Iteration 1260, lr = 0.01
I0316 17:33:51.048614 17875 solver.cpp:219] Iteration 1280 (0.00902762 iter/s, 2215.42s/20 iters), loss = 6.5064
I0316 17:33:51.048713 17875 solver.cpp:238]     Train net output #0: loss = 6.5064 (* 1 = 6.5064 loss)
I0316 17:33:51.048725 17875 sgd_solver.cpp:105] Iteration 1280, lr = 0.01
I0316 18:08:55.914314 17875 solver.cpp:331] Iteration 1300, Testing net (#0)
I0316 18:22:38.982982 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0064
I0316 18:22:38.983206 17875 solver.cpp:398]     Test net output #1: loss = 6.58766 (* 1 = 6.58766 loss)
I0316 18:24:28.305279 17875 solver.cpp:219] Iteration 1300 (0.00658489 iter/s, 3037.26s/20 iters), loss = 6.33192
I0316 18:24:28.305472 17875 solver.cpp:238]     Train net output #0: loss = 6.33192 (* 1 = 6.33192 loss)
I0316 18:24:28.305487 17875 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0316 19:01:14.534641 17875 solver.cpp:219] Iteration 1320 (0.00906524 iter/s, 2206.23s/20 iters), loss = 6.37364
I0316 19:01:14.534741 17875 solver.cpp:238]     Train net output #0: loss = 6.37364 (* 1 = 6.37364 loss)
I0316 19:01:14.534754 17875 sgd_solver.cpp:105] Iteration 1320, lr = 0.01
I0316 19:38:12.607512 17875 solver.cpp:219] Iteration 1340 (0.00901684 iter/s, 2218.07s/20 iters), loss = 6.33616
I0316 19:38:12.608669 17875 solver.cpp:238]     Train net output #0: loss = 6.33616 (* 1 = 6.33616 loss)
I0316 19:38:12.608685 17875 sgd_solver.cpp:105] Iteration 1340, lr = 0.01
I0316 20:15:16.643648 17875 solver.cpp:219] Iteration 1360 (0.00899267 iter/s, 2224.03s/20 iters), loss = 6.32479
I0316 20:15:16.643745 17875 solver.cpp:238]     Train net output #0: loss = 6.32479 (* 1 = 6.32479 loss)
I0316 20:15:16.643756 17875 sgd_solver.cpp:105] Iteration 1360, lr = 0.01
I0316 20:52:20.594971 17875 solver.cpp:219] Iteration 1380 (0.008993 iter/s, 2223.95s/20 iters), loss = 6.22383
I0316 20:52:20.595214 17875 solver.cpp:238]     Train net output #0: loss = 6.22383 (* 1 = 6.22383 loss)
I0316 20:52:20.595229 17875 sgd_solver.cpp:105] Iteration 1380, lr = 0.01
I0316 21:27:24.180156 17875 solver.cpp:331] Iteration 1400, Testing net (#0)
I0316 21:41:13.359622 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0092
I0316 21:41:13.359855 17875 solver.cpp:398]     Test net output #1: loss = 6.4822 (* 1 = 6.4822 loss)
I0316 21:43:03.247009 17875 solver.cpp:219] Iteration 1400 (0.00657322 iter/s, 3042.65s/20 iters), loss = 6.31042
I0316 21:43:03.248684 17875 solver.cpp:238]     Train net output #0: loss = 6.31042 (* 1 = 6.31042 loss)
I0316 21:43:03.248698 17875 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0316 22:19:48.426785 17875 solver.cpp:219] Iteration 1420 (0.00906956 iter/s, 2205.18s/20 iters), loss = 6.30687
I0316 22:19:48.431882 17875 solver.cpp:238]     Train net output #0: loss = 6.30687 (* 1 = 6.30687 loss)
I0316 22:19:48.431896 17875 sgd_solver.cpp:105] Iteration 1420, lr = 0.01
I0316 22:56:41.853569 17875 solver.cpp:219] Iteration 1440 (0.00903579 iter/s, 2213.42s/20 iters), loss = 6.21643
I0316 22:56:41.853863 17875 solver.cpp:238]     Train net output #0: loss = 6.21643 (* 1 = 6.21643 loss)
I0316 22:56:41.853878 17875 sgd_solver.cpp:105] Iteration 1440, lr = 0.01
I0316 23:33:24.304973 17875 solver.cpp:219] Iteration 1460 (0.00908079 iter/s, 2202.45s/20 iters), loss = 6.22491
I0316 23:33:24.305156 17875 solver.cpp:238]     Train net output #0: loss = 6.22491 (* 1 = 6.22491 loss)
I0316 23:33:24.305182 17875 sgd_solver.cpp:105] Iteration 1460, lr = 0.01
I0317 00:10:09.705319 17875 solver.cpp:219] Iteration 1480 (0.00906865 iter/s, 2205.4s/20 iters), loss = 6.20054
I0317 00:10:09.705503 17875 solver.cpp:238]     Train net output #0: loss = 6.20054 (* 1 = 6.20054 loss)
I0317 00:10:09.705515 17875 sgd_solver.cpp:105] Iteration 1480, lr = 0.01
I0317 00:45:23.139802 17875 solver.cpp:331] Iteration 1500, Testing net (#0)
I0317 00:59:28.027179 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0094
I0317 00:59:28.027326 17875 solver.cpp:398]     Test net output #1: loss = 6.42249 (* 1 = 6.42249 loss)
I0317 01:01:19.851958 17875 solver.cpp:219] Iteration 1500 (0.00651435 iter/s, 3070.15s/20 iters), loss = 6.30443
I0317 01:01:19.852093 17875 solver.cpp:238]     Train net output #0: loss = 6.30443 (* 1 = 6.30443 loss)
I0317 01:01:19.852107 17875 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0317 01:38:22.950640 17875 solver.cpp:219] Iteration 1520 (0.00899645 iter/s, 2223.1s/20 iters), loss = 6.22961
I0317 01:38:22.950781 17875 solver.cpp:238]     Train net output #0: loss = 6.22961 (* 1 = 6.22961 loss)
I0317 01:38:22.950793 17875 sgd_solver.cpp:105] Iteration 1520, lr = 0.01
I0317 02:15:22.819525 17875 solver.cpp:219] Iteration 1540 (0.00900954 iter/s, 2219.87s/20 iters), loss = 6.21398
I0317 02:15:22.819759 17875 solver.cpp:238]     Train net output #0: loss = 6.21398 (* 1 = 6.21398 loss)
I0317 02:15:22.819773 17875 sgd_solver.cpp:105] Iteration 1540, lr = 0.01
I0317 02:52:32.028470 17875 solver.cpp:219] Iteration 1560 (0.0089718 iter/s, 2229.21s/20 iters), loss = 6.1805
I0317 02:52:32.028705 17875 solver.cpp:238]     Train net output #0: loss = 6.1805 (* 1 = 6.1805 loss)
I0317 02:52:32.028720 17875 sgd_solver.cpp:105] Iteration 1560, lr = 0.01
I0317 03:29:30.127008 17875 solver.cpp:219] Iteration 1580 (0.00901673 iter/s, 2218.1s/20 iters), loss = 6.21274
I0317 03:29:30.167778 17875 solver.cpp:238]     Train net output #0: loss = 6.21274 (* 1 = 6.21274 loss)
I0317 03:29:30.167793 17875 sgd_solver.cpp:105] Iteration 1580, lr = 0.01
I0317 04:04:37.715216 17875 solver.cpp:331] Iteration 1600, Testing net (#0)
I0317 04:18:28.810677 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0134
I0317 04:18:28.810850 17875 solver.cpp:398]     Test net output #1: loss = 6.33777 (* 1 = 6.33777 loss)
I0317 04:20:19.683652 17875 solver.cpp:219] Iteration 1600 (0.00655842 iter/s, 3049.51s/20 iters), loss = 6.1043
I0317 04:20:19.686169 17875 solver.cpp:238]     Train net output #0: loss = 6.1043 (* 1 = 6.1043 loss)
I0317 04:20:19.686183 17875 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0317 04:57:09.434633 17875 solver.cpp:219] Iteration 1620 (0.00905081 iter/s, 2209.75s/20 iters), loss = 6.10815
I0317 04:57:09.434826 17875 solver.cpp:238]     Train net output #0: loss = 6.10815 (* 1 = 6.10815 loss)
I0317 04:57:09.434841 17875 sgd_solver.cpp:105] Iteration 1620, lr = 0.01
I0317 05:34:17.691411 17875 solver.cpp:219] Iteration 1640 (0.00897563 iter/s, 2228.26s/20 iters), loss = 6.11433
I0317 05:34:17.691514 17875 solver.cpp:238]     Train net output #0: loss = 6.11433 (* 1 = 6.11433 loss)
I0317 05:34:17.691525 17875 sgd_solver.cpp:105] Iteration 1640, lr = 0.01
I0317 06:11:19.209638 17875 solver.cpp:219] Iteration 1660 (0.00900285 iter/s, 2221.52s/20 iters), loss = 6.19179
I0317 06:11:19.221587 17875 solver.cpp:238]     Train net output #0: loss = 6.19179 (* 1 = 6.19179 loss)
I0317 06:11:19.221602 17875 sgd_solver.cpp:105] Iteration 1660, lr = 0.01
I0317 06:48:19.705977 17875 solver.cpp:219] Iteration 1680 (0.00900705 iter/s, 2220.48s/20 iters), loss = 6.13972
I0317 06:48:19.706218 17875 solver.cpp:238]     Train net output #0: loss = 6.13972 (* 1 = 6.13972 loss)
I0317 06:48:19.706243 17875 sgd_solver.cpp:105] Iteration 1680, lr = 0.01
I0317 07:23:56.666559 17875 solver.cpp:331] Iteration 1700, Testing net (#0)
I0317 07:38:09.533571 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0124
I0317 07:38:09.533748 17875 solver.cpp:398]     Test net output #1: loss = 6.28801 (* 1 = 6.28801 loss)
I0317 07:40:01.894562 17875 solver.cpp:219] Iteration 1700 (0.00644706 iter/s, 3102.19s/20 iters), loss = 6.05544
I0317 07:40:01.894783 17875 solver.cpp:238]     Train net output #0: loss = 6.05544 (* 1 = 6.05544 loss)
I0317 07:40:01.894798 17875 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0317 08:17:34.463577 17875 solver.cpp:219] Iteration 1720 (0.00887875 iter/s, 2252.57s/20 iters), loss = 6.06197
I0317 08:17:34.463691 17875 solver.cpp:238]     Train net output #0: loss = 6.06197 (* 1 = 6.06197 loss)
I0317 08:17:34.463703 17875 sgd_solver.cpp:105] Iteration 1720, lr = 0.01
I0317 08:55:05.244602 17875 solver.cpp:219] Iteration 1740 (0.00888581 iter/s, 2250.78s/20 iters), loss = 6.06403
I0317 08:55:05.244832 17875 solver.cpp:238]     Train net output #0: loss = 6.06403 (* 1 = 6.06403 loss)
I0317 08:55:05.244845 17875 sgd_solver.cpp:105] Iteration 1740, lr = 0.01
I0317 09:32:14.342720 17875 solver.cpp:219] Iteration 1760 (0.00897224 iter/s, 2229.1s/20 iters), loss = 6.10096
I0317 09:32:14.342823 17875 solver.cpp:238]     Train net output #0: loss = 6.10096 (* 1 = 6.10096 loss)
I0317 09:32:14.342833 17875 sgd_solver.cpp:105] Iteration 1760, lr = 0.01
I0317 10:09:44.747875 17875 solver.cpp:219] Iteration 1780 (0.00888729 iter/s, 2250.41s/20 iters), loss = 6.16526
I0317 10:09:44.747963 17875 solver.cpp:238]     Train net output #0: loss = 6.16526 (* 1 = 6.16526 loss)
I0317 10:09:44.747975 17875 sgd_solver.cpp:105] Iteration 1780, lr = 0.01
I0317 10:45:18.412297 17875 solver.cpp:331] Iteration 1800, Testing net (#0)
I0317 10:59:21.215838 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0182
I0317 10:59:21.215994 17875 solver.cpp:398]     Test net output #1: loss = 6.30551 (* 1 = 6.30551 loss)
I0317 11:01:12.496932 17875 solver.cpp:219] Iteration 1800 (0.00647721 iter/s, 3087.75s/20 iters), loss = 6.25509
I0317 11:01:12.497159 17875 solver.cpp:238]     Train net output #0: loss = 6.25509 (* 1 = 6.25509 loss)
I0317 11:01:12.497174 17875 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0317 11:38:40.985321 17875 solver.cpp:219] Iteration 1820 (0.00889487 iter/s, 2248.49s/20 iters), loss = 6.00672
I0317 11:38:40.985498 17875 solver.cpp:238]     Train net output #0: loss = 6.00672 (* 1 = 6.00672 loss)
I0317 11:38:40.985512 17875 sgd_solver.cpp:105] Iteration 1820, lr = 0.01
I0317 12:16:11.538054 17875 solver.cpp:219] Iteration 1840 (0.00888671 iter/s, 2250.55s/20 iters), loss = 5.97499
I0317 12:16:11.538295 17875 solver.cpp:238]     Train net output #0: loss = 5.97499 (* 1 = 5.97499 loss)
I0317 12:16:11.538308 17875 sgd_solver.cpp:105] Iteration 1840, lr = 0.01
I0317 12:53:21.281108 17875 solver.cpp:219] Iteration 1860 (0.00896965 iter/s, 2229.74s/20 iters), loss = 5.91593
I0317 12:53:21.281220 17875 solver.cpp:238]     Train net output #0: loss = 5.91593 (* 1 = 5.91593 loss)
I0317 12:53:21.281232 17875 sgd_solver.cpp:105] Iteration 1860, lr = 0.01
I0317 13:30:28.230545 17875 solver.cpp:219] Iteration 1880 (0.0089809 iter/s, 2226.95s/20 iters), loss = 5.88278
I0317 13:30:28.231488 17875 solver.cpp:238]     Train net output #0: loss = 5.88278 (* 1 = 5.88278 loss)
I0317 13:30:28.231503 17875 sgd_solver.cpp:105] Iteration 1880, lr = 0.01
I0317 14:05:36.813880 17875 solver.cpp:331] Iteration 1900, Testing net (#0)
I0317 14:19:02.633664 17908 data_layer.cpp:73] Restarting data prefetching from start.
I0317 14:19:36.085026 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0222
I0317 14:19:36.085202 17875 solver.cpp:398]     Test net output #1: loss = 6.14448 (* 1 = 6.14448 loss)
I0317 14:21:26.862915 17875 solver.cpp:219] Iteration 1900 (0.00653887 iter/s, 3058.63s/20 iters), loss = 6.01714
I0317 14:21:26.863184 17875 solver.cpp:238]     Train net output #0: loss = 6.01714 (* 1 = 6.01714 loss)
I0317 14:21:26.863207 17875 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0317 14:58:38.362690 17875 solver.cpp:219] Iteration 1920 (0.00896259 iter/s, 2231.5s/20 iters), loss = 5.88649
I0317 14:58:38.363179 17875 solver.cpp:238]     Train net output #0: loss = 5.88649 (* 1 = 5.88649 loss)
I0317 14:58:38.363194 17875 sgd_solver.cpp:105] Iteration 1920, lr = 0.01
I0317 15:36:04.158567 17875 solver.cpp:219] Iteration 1940 (0.00890553 iter/s, 2245.79s/20 iters), loss = 5.9822
I0317 15:36:04.158803 17875 solver.cpp:238]     Train net output #0: loss = 5.9822 (* 1 = 5.9822 loss)
I0317 15:36:04.158818 17875 sgd_solver.cpp:105] Iteration 1940, lr = 0.01
I0317 16:13:10.992496 17875 solver.cpp:219] Iteration 1960 (0.00898136 iter/s, 2226.83s/20 iters), loss = 6.00956
I0317 16:13:10.992594 17875 solver.cpp:238]     Train net output #0: loss = 6.00956 (* 1 = 6.00956 loss)
I0317 16:13:10.992606 17875 sgd_solver.cpp:105] Iteration 1960, lr = 0.01
I0317 16:50:27.194983 17875 solver.cpp:219] Iteration 1980 (0.00894374 iter/s, 2236.2s/20 iters), loss = 5.89342
I0317 16:50:27.195081 17875 solver.cpp:238]     Train net output #0: loss = 5.89342 (* 1 = 5.89342 loss)
I0317 16:50:27.195092 17875 sgd_solver.cpp:105] Iteration 1980, lr = 0.01
I0317 17:25:51.309178 17875 solver.cpp:331] Iteration 2000, Testing net (#0)
I0317 17:39:58.004108 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0282
I0317 17:39:58.004343 17875 solver.cpp:398]     Test net output #1: loss = 6.02752 (* 1 = 6.02752 loss)
I0317 17:41:50.005208 17875 solver.cpp:219] Iteration 2000 (0.00648759 iter/s, 3082.81s/20 iters), loss = 5.88685
I0317 17:41:50.005384 17875 solver.cpp:238]     Train net output #0: loss = 5.88685 (* 1 = 5.88685 loss)
I0317 17:41:50.005398 17875 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0317 18:18:53.300802 17875 solver.cpp:219] Iteration 2020 (0.00899566 iter/s, 2223.29s/20 iters), loss = 5.97798
I0317 18:18:53.300890 17875 solver.cpp:238]     Train net output #0: loss = 5.97798 (* 1 = 5.97798 loss)
I0317 18:18:53.300902 17875 sgd_solver.cpp:105] Iteration 2020, lr = 0.01
I0317 18:56:12.797240 17875 solver.cpp:219] Iteration 2040 (0.00893058 iter/s, 2239.5s/20 iters), loss = 5.8023
I0317 18:56:12.797426 17875 solver.cpp:238]     Train net output #0: loss = 5.8023 (* 1 = 5.8023 loss)
I0317 18:56:12.797441 17875 sgd_solver.cpp:105] Iteration 2040, lr = 0.01
I0317 19:33:52.673249 17875 solver.cpp:219] Iteration 2060 (0.00885005 iter/s, 2259.88s/20 iters), loss = 5.9016
I0317 19:33:52.673364 17875 solver.cpp:238]     Train net output #0: loss = 5.9016 (* 1 = 5.9016 loss)
I0317 19:33:52.673377 17875 sgd_solver.cpp:105] Iteration 2060, lr = 0.01
I0317 20:11:20.728169 17875 solver.cpp:219] Iteration 2080 (0.00889658 iter/s, 2248.05s/20 iters), loss = 5.7128
I0317 20:11:20.728360 17875 solver.cpp:238]     Train net output #0: loss = 5.7128 (* 1 = 5.7128 loss)
I0317 20:11:20.728375 17875 sgd_solver.cpp:105] Iteration 2080, lr = 0.01
I0317 20:46:42.640202 17875 solver.cpp:331] Iteration 2100, Testing net (#0)
I0317 21:00:40.184957 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0288
I0317 21:00:40.185175 17875 solver.cpp:398]     Test net output #1: loss = 6.03172 (* 1 = 6.03172 loss)
I0317 21:02:31.160095 17875 solver.cpp:219] Iteration 2100 (0.00651374 iter/s, 3070.43s/20 iters), loss = 5.73643
I0317 21:02:31.160331 17875 solver.cpp:238]     Train net output #0: loss = 5.73643 (* 1 = 5.73643 loss)
I0317 21:02:31.160346 17875 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0317 21:39:53.254987 17875 solver.cpp:219] Iteration 2120 (0.00892023 iter/s, 2242.09s/20 iters), loss = 5.82538
I0317 21:39:53.286339 17875 solver.cpp:238]     Train net output #0: loss = 5.82538 (* 1 = 5.82538 loss)
I0317 21:39:53.286352 17875 sgd_solver.cpp:105] Iteration 2120, lr = 0.01
I0317 22:16:54.166713 17875 solver.cpp:219] Iteration 2140 (0.00900544 iter/s, 2220.88s/20 iters), loss = 5.7183
I0317 22:16:54.166991 17875 solver.cpp:238]     Train net output #0: loss = 5.7183 (* 1 = 5.7183 loss)
I0317 22:16:54.167021 17875 sgd_solver.cpp:105] Iteration 2140, lr = 0.01
I0317 22:53:36.583791 17875 solver.cpp:219] Iteration 2160 (0.00908094 iter/s, 2202.42s/20 iters), loss = 5.71523
I0317 22:53:36.583894 17875 solver.cpp:238]     Train net output #0: loss = 5.71523 (* 1 = 5.71523 loss)
I0317 22:53:36.583905 17875 sgd_solver.cpp:105] Iteration 2160, lr = 0.01
I0317 23:30:34.783774 17875 solver.cpp:219] Iteration 2180 (0.00901632 iter/s, 2218.2s/20 iters), loss = 5.8051
I0317 23:30:34.783872 17875 solver.cpp:238]     Train net output #0: loss = 5.8051 (* 1 = 5.8051 loss)
I0317 23:30:34.783885 17875 sgd_solver.cpp:105] Iteration 2180, lr = 0.01
I0318 00:05:55.612745 17875 solver.cpp:331] Iteration 2200, Testing net (#0)
I0318 00:19:56.281121 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0386
I0318 00:19:56.281294 17875 solver.cpp:398]     Test net output #1: loss = 5.90028 (* 1 = 5.90028 loss)
I0318 00:21:47.407433 17875 solver.cpp:219] Iteration 2200 (0.0065091 iter/s, 3072.62s/20 iters), loss = 5.63592
I0318 00:21:47.407619 17875 solver.cpp:238]     Train net output #0: loss = 5.63592 (* 1 = 5.63592 loss)
I0318 00:21:47.407634 17875 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0318 00:59:00.291054 17875 solver.cpp:219] Iteration 2220 (0.00895703 iter/s, 2232.88s/20 iters), loss = 5.6346
I0318 00:59:00.291290 17875 solver.cpp:238]     Train net output #0: loss = 5.6346 (* 1 = 5.6346 loss)
I0318 00:59:00.291306 17875 sgd_solver.cpp:105] Iteration 2220, lr = 0.01
I0318 01:35:53.939172 17875 solver.cpp:219] Iteration 2240 (0.00903486 iter/s, 2213.65s/20 iters), loss = 5.65554
I0318 01:35:53.939268 17875 solver.cpp:238]     Train net output #0: loss = 5.65554 (* 1 = 5.65554 loss)
I0318 01:35:53.939280 17875 sgd_solver.cpp:105] Iteration 2240, lr = 0.01
I0318 02:12:45.962788 17875 solver.cpp:219] Iteration 2260 (0.0090415 iter/s, 2212.02s/20 iters), loss = 5.68021
I0318 02:12:45.962888 17875 solver.cpp:238]     Train net output #0: loss = 5.68021 (* 1 = 5.68021 loss)
I0318 02:12:45.962898 17875 sgd_solver.cpp:105] Iteration 2260, lr = 0.01
I0318 02:49:42.378990 17875 solver.cpp:219] Iteration 2280 (0.00902358 iter/s, 2216.42s/20 iters), loss = 5.57194
I0318 02:49:42.379225 17875 solver.cpp:238]     Train net output #0: loss = 5.57194 (* 1 = 5.57194 loss)
I0318 02:49:42.379240 17875 sgd_solver.cpp:105] Iteration 2280, lr = 0.01
I0318 03:25:01.513108 17875 solver.cpp:331] Iteration 2300, Testing net (#0)
I0318 03:38:52.843411 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0374
I0318 03:38:52.849506 17875 solver.cpp:398]     Test net output #1: loss = 5.85628 (* 1 = 5.85628 loss)
I0318 03:40:43.257344 17875 solver.cpp:219] Iteration 2300 (0.00653407 iter/s, 3060.88s/20 iters), loss = 5.66484
I0318 03:40:43.257525 17875 solver.cpp:238]     Train net output #0: loss = 5.66484 (* 1 = 5.66484 loss)
I0318 03:40:43.257537 17875 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0318 04:17:39.439102 17875 solver.cpp:219] Iteration 2320 (0.00902453 iter/s, 2216.18s/20 iters), loss = 5.57061
I0318 04:17:39.439241 17875 solver.cpp:238]     Train net output #0: loss = 5.57061 (* 1 = 5.57061 loss)
I0318 04:17:39.439254 17875 sgd_solver.cpp:105] Iteration 2320, lr = 0.01
I0318 04:54:40.543773 17875 solver.cpp:219] Iteration 2340 (0.00900453 iter/s, 2221.1s/20 iters), loss = 5.53121
I0318 04:54:40.543872 17875 solver.cpp:238]     Train net output #0: loss = 5.53121 (* 1 = 5.53121 loss)
I0318 04:54:40.543884 17875 sgd_solver.cpp:105] Iteration 2340, lr = 0.01
I0318 05:31:26.465421 17875 solver.cpp:219] Iteration 2360 (0.00906651 iter/s, 2205.92s/20 iters), loss = 5.59437
I0318 05:31:26.465569 17875 solver.cpp:238]     Train net output #0: loss = 5.59437 (* 1 = 5.59437 loss)
I0318 05:31:26.465582 17875 sgd_solver.cpp:105] Iteration 2360, lr = 0.01
I0318 06:08:32.574257 17875 solver.cpp:219] Iteration 2380 (0.00898429 iter/s, 2226.11s/20 iters), loss = 5.64551
I0318 06:08:32.574414 17875 solver.cpp:238]     Train net output #0: loss = 5.64551 (* 1 = 5.64551 loss)
I0318 06:08:32.574429 17875 sgd_solver.cpp:105] Iteration 2380, lr = 0.01
I0318 06:43:49.563627 17875 solver.cpp:331] Iteration 2400, Testing net (#0)
I0318 06:57:34.812178 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0404
I0318 06:57:34.812275 17875 solver.cpp:398]     Test net output #1: loss = 5.82687 (* 1 = 5.82687 loss)
I0318 06:59:24.431560 17875 solver.cpp:219] Iteration 2400 (0.00655339 iter/s, 3051.86s/20 iters), loss = 5.5264
I0318 06:59:24.431655 17875 solver.cpp:238]     Train net output #0: loss = 5.5264 (* 1 = 5.5264 loss)
I0318 06:59:24.431668 17875 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0318 07:36:10.667040 17875 solver.cpp:219] Iteration 2420 (0.00906522 iter/s, 2206.24s/20 iters), loss = 5.4246
I0318 07:36:10.667302 17875 solver.cpp:238]     Train net output #0: loss = 5.4246 (* 1 = 5.4246 loss)
I0318 07:36:10.667315 17875 sgd_solver.cpp:105] Iteration 2420, lr = 0.01
I0318 08:12:46.688858 17875 solver.cpp:219] Iteration 2440 (0.00910738 iter/s, 2196.02s/20 iters), loss = 5.54532
I0318 08:12:46.689002 17875 solver.cpp:238]     Train net output #0: loss = 5.54532 (* 1 = 5.54532 loss)
I0318 08:12:46.689013 17875 sgd_solver.cpp:105] Iteration 2440, lr = 0.01
I0318 08:49:27.618172 17875 solver.cpp:219] Iteration 2460 (0.00908707 iter/s, 2200.93s/20 iters), loss = 5.5048
I0318 08:49:27.620060 17875 solver.cpp:238]     Train net output #0: loss = 5.5048 (* 1 = 5.5048 loss)
I0318 08:49:27.620072 17875 sgd_solver.cpp:105] Iteration 2460, lr = 0.01
I0318 09:26:24.529083 17875 solver.cpp:219] Iteration 2480 (0.00902157 iter/s, 2216.91s/20 iters), loss = 5.54602
I0318 09:26:24.529320 17875 solver.cpp:238]     Train net output #0: loss = 5.54602 (* 1 = 5.54602 loss)
I0318 09:26:24.529335 17875 sgd_solver.cpp:105] Iteration 2480, lr = 0.01
I0318 10:01:29.010609 17875 solver.cpp:331] Iteration 2500, Testing net (#0)
I0318 10:15:16.327373 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0498
I0318 10:15:16.327466 17875 solver.cpp:398]     Test net output #1: loss = 5.63867 (* 1 = 5.63867 loss)
I0318 10:17:05.870365 17875 solver.cpp:219] Iteration 2500 (0.00657605 iter/s, 3041.34s/20 iters), loss = 5.55872
I0318 10:17:05.870576 17875 solver.cpp:238]     Train net output #0: loss = 5.55872 (* 1 = 5.55872 loss)
I0318 10:17:05.870590 17875 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0318 10:53:40.727461 17875 solver.cpp:219] Iteration 2520 (0.00911222 iter/s, 2194.86s/20 iters), loss = 5.35457
I0318 10:53:40.727571 17875 solver.cpp:238]     Train net output #0: loss = 5.35457 (* 1 = 5.35457 loss)
I0318 10:53:40.727584 17875 sgd_solver.cpp:105] Iteration 2520, lr = 0.01
I0318 11:30:27.458631 17875 solver.cpp:219] Iteration 2540 (0.00906318 iter/s, 2206.73s/20 iters), loss = 5.53489
I0318 11:30:27.458876 17875 solver.cpp:238]     Train net output #0: loss = 5.53489 (* 1 = 5.53489 loss)
I0318 11:30:27.458891 17875 sgd_solver.cpp:105] Iteration 2540, lr = 0.01
I0318 12:07:39.330523 17875 solver.cpp:219] Iteration 2560 (0.00896109 iter/s, 2231.87s/20 iters), loss = 5.66524
I0318 12:07:39.330778 17875 solver.cpp:238]     Train net output #0: loss = 5.66524 (* 1 = 5.66524 loss)
I0318 12:07:39.330792 17875 sgd_solver.cpp:105] Iteration 2560, lr = 0.01
I0318 12:44:23.298732 17875 solver.cpp:219] Iteration 2580 (0.00907455 iter/s, 2203.97s/20 iters), loss = 5.38065
I0318 12:44:23.298835 17875 solver.cpp:238]     Train net output #0: loss = 5.38065 (* 1 = 5.38065 loss)
I0318 12:44:23.298847 17875 sgd_solver.cpp:105] Iteration 2580, lr = 0.01
I0318 13:18:58.028625 17875 solver.cpp:331] Iteration 2600, Testing net (#0)
I0318 13:32:42.769822 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0532
I0318 13:32:42.769918 17875 solver.cpp:398]     Test net output #1: loss = 5.61095 (* 1 = 5.61095 loss)
I0318 13:34:32.195317 17875 solver.cpp:219] Iteration 2600 (0.00664696 iter/s, 3008.9s/20 iters), loss = 5.29892
I0318 13:34:32.195644 17875 solver.cpp:238]     Train net output #0: loss = 5.29892 (* 1 = 5.29892 loss)
I0318 13:34:32.195658 17875 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0318 14:11:17.126806 17875 solver.cpp:219] Iteration 2620 (0.00907058 iter/s, 2204.93s/20 iters), loss = 5.44551
I0318 14:11:17.127094 17875 solver.cpp:238]     Train net output #0: loss = 5.44551 (* 1 = 5.44551 loss)
I0318 14:11:17.127107 17875 sgd_solver.cpp:105] Iteration 2620, lr = 0.01
I0318 14:48:00.802108 17875 solver.cpp:219] Iteration 2640 (0.00907575 iter/s, 2203.68s/20 iters), loss = 5.38078
I0318 14:48:00.802209 17875 solver.cpp:238]     Train net output #0: loss = 5.38078 (* 1 = 5.38078 loss)
I0318 14:48:00.802222 17875 sgd_solver.cpp:105] Iteration 2640, lr = 0.01
I0318 15:24:44.364532 17875 solver.cpp:219] Iteration 2660 (0.00907621 iter/s, 2203.56s/20 iters), loss = 5.39512
I0318 15:24:44.364634 17875 solver.cpp:238]     Train net output #0: loss = 5.39512 (* 1 = 5.39512 loss)
I0318 15:24:44.364645 17875 sgd_solver.cpp:105] Iteration 2660, lr = 0.01
I0318 16:01:26.311857 17875 solver.cpp:219] Iteration 2680 (0.00908287 iter/s, 2201.95s/20 iters), loss = 5.34916
I0318 16:01:26.312042 17875 solver.cpp:238]     Train net output #0: loss = 5.34916 (* 1 = 5.34916 loss)
I0318 16:01:26.312057 17875 sgd_solver.cpp:105] Iteration 2680, lr = 0.01
I0318 16:36:13.180188 17875 solver.cpp:331] Iteration 2700, Testing net (#0)
I0318 16:49:49.043143 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0582
I0318 16:49:49.043365 17875 solver.cpp:398]     Test net output #1: loss = 5.5626 (* 1 = 5.5626 loss)
I0318 16:51:37.266111 17875 solver.cpp:219] Iteration 2700 (0.00664241 iter/s, 3010.95s/20 iters), loss = 5.40282
I0318 16:51:37.266216 17875 solver.cpp:238]     Train net output #0: loss = 5.40282 (* 1 = 5.40282 loss)
I0318 16:51:37.266227 17875 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0318 17:28:22.294000 17875 solver.cpp:219] Iteration 2720 (0.00907018 iter/s, 2205.03s/20 iters), loss = 5.49007
I0318 17:28:22.318589 17875 solver.cpp:238]     Train net output #0: loss = 5.49007 (* 1 = 5.49007 loss)
I0318 17:28:22.318603 17875 sgd_solver.cpp:105] Iteration 2720, lr = 0.01
I0318 18:05:04.381853 17875 solver.cpp:219] Iteration 2740 (0.00908239 iter/s, 2202.06s/20 iters), loss = 5.36051
I0318 18:05:04.382091 17875 solver.cpp:238]     Train net output #0: loss = 5.36051 (* 1 = 5.36051 loss)
I0318 18:05:04.382107 17875 sgd_solver.cpp:105] Iteration 2740, lr = 0.01
I0318 18:41:47.911468 17875 solver.cpp:219] Iteration 2760 (0.00907635 iter/s, 2203.53s/20 iters), loss = 5.27053
I0318 18:41:47.914443 17875 solver.cpp:238]     Train net output #0: loss = 5.27053 (* 1 = 5.27053 loss)
I0318 18:41:47.914459 17875 sgd_solver.cpp:105] Iteration 2760, lr = 0.01
I0318 19:18:05.919499 17875 solver.cpp:219] Iteration 2780 (0.00918272 iter/s, 2178s/20 iters), loss = 5.37592
I0318 19:18:05.919739 17875 solver.cpp:238]     Train net output #0: loss = 5.37592 (* 1 = 5.37592 loss)
I0318 19:18:05.919752 17875 sgd_solver.cpp:105] Iteration 2780, lr = 0.01
I0318 19:52:45.694288 17875 solver.cpp:331] Iteration 2800, Testing net (#0)
I0318 20:06:20.043786 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0658
I0318 20:06:20.043994 17875 solver.cpp:398]     Test net output #1: loss = 5.44091 (* 1 = 5.44091 loss)
I0318 20:08:08.280115 17875 solver.cpp:219] Iteration 2800 (0.00666143 iter/s, 3002.36s/20 iters), loss = 5.28051
I0318 20:08:08.280207 17875 solver.cpp:238]     Train net output #0: loss = 5.28051 (* 1 = 5.28051 loss)
I0318 20:08:08.280220 17875 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0318 20:44:29.707938 17875 solver.cpp:219] Iteration 2820 (0.00916831 iter/s, 2181.43s/20 iters), loss = 5.20832
I0318 20:44:29.708120 17875 solver.cpp:238]     Train net output #0: loss = 5.20832 (* 1 = 5.20832 loss)
I0318 20:44:29.708135 17875 sgd_solver.cpp:105] Iteration 2820, lr = 0.01
I0318 21:20:58.322079 17875 solver.cpp:219] Iteration 2840 (0.00913821 iter/s, 2188.61s/20 iters), loss = 5.38823
I0318 21:20:58.322178 17875 solver.cpp:238]     Train net output #0: loss = 5.38823 (* 1 = 5.38823 loss)
I0318 21:20:58.322190 17875 sgd_solver.cpp:105] Iteration 2840, lr = 0.01
I0318 21:57:52.855806 17875 solver.cpp:219] Iteration 2860 (0.00903125 iter/s, 2214.53s/20 iters), loss = 5.30194
I0318 21:57:52.856091 17875 solver.cpp:238]     Train net output #0: loss = 5.30194 (* 1 = 5.30194 loss)
I0318 21:57:52.856106 17875 sgd_solver.cpp:105] Iteration 2860, lr = 0.01
I0318 22:34:48.919513 17875 solver.cpp:219] Iteration 2880 (0.00902501 iter/s, 2216.06s/20 iters), loss = 5.39153
I0318 22:34:48.919739 17875 solver.cpp:238]     Train net output #0: loss = 5.39153 (* 1 = 5.39153 loss)
I0318 22:34:48.919752 17875 sgd_solver.cpp:105] Iteration 2880, lr = 0.01
I0318 23:09:38.599931 17875 solver.cpp:331] Iteration 2900, Testing net (#0)
I0318 23:22:45.413395 17908 data_layer.cpp:73] Restarting data prefetching from start.
I0318 23:23:18.104773 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0704
I0318 23:23:18.104866 17875 solver.cpp:398]     Test net output #1: loss = 5.41969 (* 1 = 5.41969 loss)
I0318 23:25:07.569646 17875 solver.cpp:219] Iteration 2900 (0.00662548 iter/s, 3018.65s/20 iters), loss = 5.24147
I0318 23:25:07.569744 17875 solver.cpp:238]     Train net output #0: loss = 5.24147 (* 1 = 5.24147 loss)
I0318 23:25:07.569756 17875 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0319 00:01:49.151876 17875 solver.cpp:219] Iteration 2920 (0.00908438 iter/s, 2201.58s/20 iters), loss = 5.29873
I0319 00:01:49.152047 17875 solver.cpp:238]     Train net output #0: loss = 5.29873 (* 1 = 5.29873 loss)
I0319 00:01:49.152062 17875 sgd_solver.cpp:105] Iteration 2920, lr = 0.01
I0319 00:38:47.397022 17875 solver.cpp:219] Iteration 2940 (0.00901614 iter/s, 2218.24s/20 iters), loss = 5.21949
I0319 00:38:47.401476 17875 solver.cpp:238]     Train net output #0: loss = 5.21949 (* 1 = 5.21949 loss)
I0319 00:38:47.401489 17875 sgd_solver.cpp:105] Iteration 2940, lr = 0.01
I0319 01:15:26.438246 17875 solver.cpp:219] Iteration 2960 (0.00909489 iter/s, 2199.04s/20 iters), loss = 5.20542
I0319 01:15:26.473386 17875 solver.cpp:238]     Train net output #0: loss = 5.20542 (* 1 = 5.20542 loss)
I0319 01:15:26.473400 17875 sgd_solver.cpp:105] Iteration 2960, lr = 0.01
I0319 01:52:05.668222 17875 solver.cpp:219] Iteration 2980 (0.00909424 iter/s, 2199.19s/20 iters), loss = 5.25554
I0319 01:52:05.668316 17875 solver.cpp:238]     Train net output #0: loss = 5.25554 (* 1 = 5.25554 loss)
I0319 01:52:05.668329 17875 sgd_solver.cpp:105] Iteration 2980, lr = 0.01
I0319 02:26:57.540174 17875 solver.cpp:448] Snapshotting to binary proto file models/caffenet_proj/caffenet_train_iter_3000.caffemodel
I0319 02:27:09.398883 17875 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/caffenet_proj/caffenet_train_iter_3000.solverstate
I0319 02:27:51.689391 17875 solver.cpp:311] Iteration 3000, loss = 5.16021
I0319 02:27:51.689605 17875 solver.cpp:331] Iteration 3000, Testing net (#0)
I0319 02:41:30.495167 17875 solver.cpp:398]     Test net output #0: accuracy = 0.0768
I0319 02:41:30.495388 17875 solver.cpp:398]     Test net output #1: loss = 5.31319 (* 1 = 5.31319 loss)
I0319 02:41:30.495400 17875 solver.cpp:316] Optimization Done.
I0319 02:41:30.495406 17875 caffe.cpp:259] Optimization Done.
